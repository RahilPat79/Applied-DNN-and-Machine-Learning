{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "path = \"./data/\"\n",
    "    \n",
    "filename = os.path.join(path,\"iris.csv\")    \n",
    "df = pd.read_csv(filename,na_values=['NA','?'])\n",
    "\n",
    "\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rahil\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\rahil\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 150 samples, validate on 38 samples\n",
      "Epoch 1/1000\n",
      "0s - loss: 1.5274 - val_loss: 1.6263\n",
      "Epoch 2/1000\n",
      "0s - loss: 1.4797 - val_loss: 1.5703\n",
      "Epoch 3/1000\n",
      "0s - loss: 1.4392 - val_loss: 1.5217\n",
      "Epoch 4/1000\n",
      "0s - loss: 1.4037 - val_loss: 1.4804\n",
      "Epoch 5/1000\n",
      "0s - loss: 1.3701 - val_loss: 1.4448\n",
      "Epoch 6/1000\n",
      "0s - loss: 1.3442 - val_loss: 1.4129\n",
      "Epoch 7/1000\n",
      "0s - loss: 1.3209 - val_loss: 1.3851\n",
      "Epoch 8/1000\n",
      "0s - loss: 1.3035 - val_loss: 1.3595\n",
      "Epoch 9/1000\n",
      "0s - loss: 1.2854 - val_loss: 1.3373\n",
      "Epoch 10/1000\n",
      "0s - loss: 1.2700 - val_loss: 1.3177\n",
      "Epoch 11/1000\n",
      "0s - loss: 1.2548 - val_loss: 1.3011\n",
      "Epoch 12/1000\n",
      "0s - loss: 1.2432 - val_loss: 1.2854\n",
      "Epoch 13/1000\n",
      "0s - loss: 1.2311 - val_loss: 1.2710\n",
      "Epoch 14/1000\n",
      "0s - loss: 1.2211 - val_loss: 1.2576\n",
      "Epoch 15/1000\n",
      "0s - loss: 1.2107 - val_loss: 1.2457\n",
      "Epoch 16/1000\n",
      "0s - loss: 1.2019 - val_loss: 1.2342\n",
      "Epoch 17/1000\n",
      "0s - loss: 1.1943 - val_loss: 1.2231\n",
      "Epoch 18/1000\n",
      "0s - loss: 1.1856 - val_loss: 1.2133\n",
      "Epoch 19/1000\n",
      "0s - loss: 1.1788 - val_loss: 1.2038\n",
      "Epoch 20/1000\n",
      "0s - loss: 1.1714 - val_loss: 1.1954\n",
      "Epoch 21/1000\n",
      "0s - loss: 1.1649 - val_loss: 1.1878\n",
      "Epoch 22/1000\n",
      "0s - loss: 1.1594 - val_loss: 1.1802\n",
      "Epoch 23/1000\n",
      "0s - loss: 1.1533 - val_loss: 1.1736\n",
      "Epoch 24/1000\n",
      "0s - loss: 1.1484 - val_loss: 1.1671\n",
      "Epoch 25/1000\n",
      "0s - loss: 1.1430 - val_loss: 1.1615\n",
      "Epoch 26/1000\n",
      "0s - loss: 1.1386 - val_loss: 1.1559\n",
      "Epoch 27/1000\n",
      "0s - loss: 1.1346 - val_loss: 1.1502\n",
      "Epoch 28/1000\n",
      "0s - loss: 1.1301 - val_loss: 1.1452\n",
      "Epoch 29/1000\n",
      "0s - loss: 1.1261 - val_loss: 1.1405\n",
      "Epoch 30/1000\n",
      "0s - loss: 1.1223 - val_loss: 1.1361\n",
      "Epoch 31/1000\n",
      "0s - loss: 1.1187 - val_loss: 1.1318\n",
      "Epoch 32/1000\n",
      "0s - loss: 1.1154 - val_loss: 1.1274\n",
      "Epoch 33/1000\n",
      "0s - loss: 1.1117 - val_loss: 1.1235\n",
      "Epoch 34/1000\n",
      "0s - loss: 1.1085 - val_loss: 1.1195\n",
      "Epoch 35/1000\n",
      "0s - loss: 1.1053 - val_loss: 1.1158\n",
      "Epoch 36/1000\n",
      "0s - loss: 1.1020 - val_loss: 1.1119\n",
      "Epoch 37/1000\n",
      "0s - loss: 1.0988 - val_loss: 1.1082\n",
      "Epoch 38/1000\n",
      "0s - loss: 1.0956 - val_loss: 1.1046\n",
      "Epoch 39/1000\n",
      "0s - loss: 1.0924 - val_loss: 1.1008\n",
      "Epoch 40/1000\n",
      "0s - loss: 1.0892 - val_loss: 1.0970\n",
      "Epoch 41/1000\n",
      "0s - loss: 1.0858 - val_loss: 1.0933\n",
      "Epoch 42/1000\n",
      "0s - loss: 1.0824 - val_loss: 1.0895\n",
      "Epoch 43/1000\n",
      "0s - loss: 1.0790 - val_loss: 1.0855\n",
      "Epoch 44/1000\n",
      "0s - loss: 1.0755 - val_loss: 1.0814\n",
      "Epoch 45/1000\n",
      "0s - loss: 1.0720 - val_loss: 1.0772\n",
      "Epoch 46/1000\n",
      "0s - loss: 1.0681 - val_loss: 1.0732\n",
      "Epoch 47/1000\n",
      "0s - loss: 1.0642 - val_loss: 1.0689\n",
      "Epoch 48/1000\n",
      "0s - loss: 1.0603 - val_loss: 1.0644\n",
      "Epoch 49/1000\n",
      "0s - loss: 1.0562 - val_loss: 1.0600\n",
      "Epoch 50/1000\n",
      "0s - loss: 1.0518 - val_loss: 1.0556\n",
      "Epoch 51/1000\n",
      "0s - loss: 1.0474 - val_loss: 1.0511\n",
      "Epoch 52/1000\n",
      "0s - loss: 1.0429 - val_loss: 1.0464\n",
      "Epoch 53/1000\n",
      "0s - loss: 1.0383 - val_loss: 1.0417\n",
      "Epoch 54/1000\n",
      "0s - loss: 1.0336 - val_loss: 1.0364\n",
      "Epoch 55/1000\n",
      "0s - loss: 1.0286 - val_loss: 1.0312\n",
      "Epoch 56/1000\n",
      "0s - loss: 1.0234 - val_loss: 1.0256\n",
      "Epoch 57/1000\n",
      "0s - loss: 1.0179 - val_loss: 1.0199\n",
      "Epoch 58/1000\n",
      "0s - loss: 1.0125 - val_loss: 1.0137\n",
      "Epoch 59/1000\n",
      "0s - loss: 1.0071 - val_loss: 1.0072\n",
      "Epoch 60/1000\n",
      "0s - loss: 1.0009 - val_loss: 1.0006\n",
      "Epoch 61/1000\n",
      "0s - loss: 0.9947 - val_loss: 0.9941\n",
      "Epoch 62/1000\n",
      "0s - loss: 0.9881 - val_loss: 0.9874\n",
      "Epoch 63/1000\n",
      "0s - loss: 0.9815 - val_loss: 0.9797\n",
      "Epoch 64/1000\n",
      "0s - loss: 0.9745 - val_loss: 0.9718\n",
      "Epoch 65/1000\n",
      "0s - loss: 0.9672 - val_loss: 0.9637\n",
      "Epoch 66/1000\n",
      "0s - loss: 0.9597 - val_loss: 0.9550\n",
      "Epoch 67/1000\n",
      "0s - loss: 0.9517 - val_loss: 0.9463\n",
      "Epoch 68/1000\n",
      "0s - loss: 0.9438 - val_loss: 0.9371\n",
      "Epoch 69/1000\n",
      "0s - loss: 0.9352 - val_loss: 0.9280\n",
      "Epoch 70/1000\n",
      "0s - loss: 0.9273 - val_loss: 0.9185\n",
      "Epoch 71/1000\n",
      "0s - loss: 0.9186 - val_loss: 0.9102\n",
      "Epoch 72/1000\n",
      "0s - loss: 0.9111 - val_loss: 0.9024\n",
      "Epoch 73/1000\n",
      "0s - loss: 0.9031 - val_loss: 0.8954\n",
      "Epoch 74/1000\n",
      "0s - loss: 0.8956 - val_loss: 0.8881\n",
      "Epoch 75/1000\n",
      "0s - loss: 0.8882 - val_loss: 0.8808\n",
      "Epoch 76/1000\n",
      "0s - loss: 0.8808 - val_loss: 0.8735\n",
      "Epoch 77/1000\n",
      "0s - loss: 0.8740 - val_loss: 0.8668\n",
      "Epoch 78/1000\n",
      "0s - loss: 0.8670 - val_loss: 0.8597\n",
      "Epoch 79/1000\n",
      "0s - loss: 0.8602 - val_loss: 0.8530\n",
      "Epoch 80/1000\n",
      "0s - loss: 0.8541 - val_loss: 0.8466\n",
      "Epoch 81/1000\n",
      "0s - loss: 0.8478 - val_loss: 0.8406\n",
      "Epoch 82/1000\n",
      "0s - loss: 0.8421 - val_loss: 0.8349\n",
      "Epoch 83/1000\n",
      "0s - loss: 0.8363 - val_loss: 0.8297\n",
      "Epoch 84/1000\n",
      "0s - loss: 0.8308 - val_loss: 0.8244\n",
      "Epoch 85/1000\n",
      "0s - loss: 0.8254 - val_loss: 0.8187\n",
      "Epoch 86/1000\n",
      "0s - loss: 0.8204 - val_loss: 0.8131\n",
      "Epoch 87/1000\n",
      "0s - loss: 0.8152 - val_loss: 0.8082\n",
      "Epoch 88/1000\n",
      "0s - loss: 0.8103 - val_loss: 0.8030\n",
      "Epoch 89/1000\n",
      "0s - loss: 0.8055 - val_loss: 0.7981\n",
      "Epoch 90/1000\n",
      "0s - loss: 0.8010 - val_loss: 0.7931\n",
      "Epoch 91/1000\n",
      "0s - loss: 0.7964 - val_loss: 0.7885\n",
      "Epoch 92/1000\n",
      "0s - loss: 0.7919 - val_loss: 0.7839\n",
      "Epoch 93/1000\n",
      "0s - loss: 0.7877 - val_loss: 0.7794\n",
      "Epoch 94/1000\n",
      "0s - loss: 0.7835 - val_loss: 0.7753\n",
      "Epoch 95/1000\n",
      "0s - loss: 0.7796 - val_loss: 0.7711\n",
      "Epoch 96/1000\n",
      "0s - loss: 0.7755 - val_loss: 0.7669\n",
      "Epoch 97/1000\n",
      "0s - loss: 0.7717 - val_loss: 0.7628\n",
      "Epoch 98/1000\n",
      "0s - loss: 0.7679 - val_loss: 0.7589\n",
      "Epoch 99/1000\n",
      "0s - loss: 0.7644 - val_loss: 0.7551\n",
      "Epoch 100/1000\n",
      "0s - loss: 0.7606 - val_loss: 0.7515\n",
      "Epoch 101/1000\n",
      "0s - loss: 0.7571 - val_loss: 0.7479\n",
      "Epoch 102/1000\n",
      "0s - loss: 0.7537 - val_loss: 0.7444\n",
      "Epoch 103/1000\n",
      "0s - loss: 0.7505 - val_loss: 0.7409\n",
      "Epoch 104/1000\n",
      "0s - loss: 0.7470 - val_loss: 0.7375\n",
      "Epoch 105/1000\n",
      "0s - loss: 0.7437 - val_loss: 0.7341\n",
      "Epoch 106/1000\n",
      "0s - loss: 0.7407 - val_loss: 0.7310\n",
      "Epoch 107/1000\n",
      "0s - loss: 0.7375 - val_loss: 0.7278\n",
      "Epoch 108/1000\n",
      "0s - loss: 0.7345 - val_loss: 0.7246\n",
      "Epoch 109/1000\n",
      "0s - loss: 0.7315 - val_loss: 0.7215\n",
      "Epoch 110/1000\n",
      "0s - loss: 0.7286 - val_loss: 0.7186\n",
      "Epoch 111/1000\n",
      "0s - loss: 0.7257 - val_loss: 0.7156\n",
      "Epoch 112/1000\n",
      "0s - loss: 0.7229 - val_loss: 0.7128\n",
      "Epoch 113/1000\n",
      "0s - loss: 0.7203 - val_loss: 0.7101\n",
      "Epoch 114/1000\n",
      "0s - loss: 0.7175 - val_loss: 0.7074\n",
      "Epoch 115/1000\n",
      "0s - loss: 0.7148 - val_loss: 0.7046\n",
      "Epoch 116/1000\n",
      "0s - loss: 0.7122 - val_loss: 0.7019\n",
      "Epoch 117/1000\n",
      "0s - loss: 0.7097 - val_loss: 0.6992\n",
      "Epoch 118/1000\n",
      "0s - loss: 0.7072 - val_loss: 0.6965\n",
      "Epoch 119/1000\n",
      "0s - loss: 0.7048 - val_loss: 0.6940\n",
      "Epoch 120/1000\n",
      "0s - loss: 0.7022 - val_loss: 0.6914\n",
      "Epoch 121/1000\n",
      "0s - loss: 0.7000 - val_loss: 0.6887\n",
      "Epoch 122/1000\n",
      "0s - loss: 0.6975 - val_loss: 0.6863\n",
      "Epoch 123/1000\n",
      "0s - loss: 0.6951 - val_loss: 0.6838\n",
      "Epoch 124/1000\n",
      "0s - loss: 0.6930 - val_loss: 0.6813\n",
      "Epoch 125/1000\n",
      "0s - loss: 0.6909 - val_loss: 0.6791\n",
      "Epoch 126/1000\n",
      "0s - loss: 0.6884 - val_loss: 0.6767\n",
      "Epoch 127/1000\n",
      "0s - loss: 0.6860 - val_loss: 0.6745\n",
      "Epoch 128/1000\n",
      "0s - loss: 0.6838 - val_loss: 0.6722\n",
      "Epoch 129/1000\n",
      "0s - loss: 0.6817 - val_loss: 0.6698\n",
      "Epoch 130/1000\n",
      "0s - loss: 0.6797 - val_loss: 0.6676\n",
      "Epoch 131/1000\n",
      "0s - loss: 0.6774 - val_loss: 0.6653\n",
      "Epoch 132/1000\n",
      "0s - loss: 0.6754 - val_loss: 0.6631\n",
      "Epoch 133/1000\n",
      "0s - loss: 0.6738 - val_loss: 0.6612\n",
      "Epoch 134/1000\n",
      "0s - loss: 0.6717 - val_loss: 0.6590\n",
      "Epoch 135/1000\n",
      "0s - loss: 0.6693 - val_loss: 0.6570\n",
      "Epoch 136/1000\n",
      "0s - loss: 0.6674 - val_loss: 0.6550\n",
      "Epoch 137/1000\n",
      "0s - loss: 0.6655 - val_loss: 0.6529\n",
      "Epoch 138/1000\n",
      "0s - loss: 0.6634 - val_loss: 0.6509\n",
      "Epoch 139/1000\n",
      "0s - loss: 0.6615 - val_loss: 0.6489\n",
      "Epoch 140/1000\n",
      "0s - loss: 0.6596 - val_loss: 0.6470\n",
      "Epoch 141/1000\n",
      "0s - loss: 0.6578 - val_loss: 0.6451\n",
      "Epoch 142/1000\n",
      "0s - loss: 0.6560 - val_loss: 0.6433\n",
      "Epoch 143/1000\n",
      "0s - loss: 0.6542 - val_loss: 0.6414\n",
      "Epoch 144/1000\n",
      "0s - loss: 0.6525 - val_loss: 0.6394\n",
      "Epoch 145/1000\n",
      "0s - loss: 0.6506 - val_loss: 0.6376\n",
      "Epoch 146/1000\n",
      "0s - loss: 0.6489 - val_loss: 0.6358\n",
      "Epoch 147/1000\n",
      "0s - loss: 0.6472 - val_loss: 0.6340\n",
      "Epoch 148/1000\n",
      "0s - loss: 0.6455 - val_loss: 0.6320\n",
      "Epoch 149/1000\n",
      "0s - loss: 0.6438 - val_loss: 0.6302\n",
      "Epoch 150/1000\n",
      "0s - loss: 0.6420 - val_loss: 0.6285\n",
      "Epoch 151/1000\n",
      "0s - loss: 0.6403 - val_loss: 0.6267\n",
      "Epoch 152/1000\n",
      "0s - loss: 0.6386 - val_loss: 0.6249\n",
      "Epoch 153/1000\n",
      "0s - loss: 0.6374 - val_loss: 0.6230\n",
      "Epoch 154/1000\n",
      "0s - loss: 0.6354 - val_loss: 0.6212\n",
      "Epoch 155/1000\n",
      "0s - loss: 0.6338 - val_loss: 0.6196\n",
      "Epoch 156/1000\n",
      "0s - loss: 0.6322 - val_loss: 0.6179\n",
      "Epoch 157/1000\n",
      "0s - loss: 0.6306 - val_loss: 0.6163\n",
      "Epoch 158/1000\n",
      "0s - loss: 0.6293 - val_loss: 0.6148\n",
      "Epoch 159/1000\n",
      "0s - loss: 0.6275 - val_loss: 0.6132\n",
      "Epoch 160/1000\n",
      "0s - loss: 0.6260 - val_loss: 0.6117\n",
      "Epoch 161/1000\n",
      "0s - loss: 0.6248 - val_loss: 0.6098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/1000\n",
      "0s - loss: 0.6230 - val_loss: 0.6082\n",
      "Epoch 163/1000\n",
      "0s - loss: 0.6216 - val_loss: 0.6066\n",
      "Epoch 164/1000\n",
      "0s - loss: 0.6203 - val_loss: 0.6052\n",
      "Epoch 165/1000\n",
      "0s - loss: 0.6185 - val_loss: 0.6036\n",
      "Epoch 166/1000\n",
      "0s - loss: 0.6172 - val_loss: 0.6020\n",
      "Epoch 167/1000\n",
      "0s - loss: 0.6157 - val_loss: 0.6006\n",
      "Epoch 168/1000\n",
      "0s - loss: 0.6142 - val_loss: 0.5991\n",
      "Epoch 169/1000\n",
      "0s - loss: 0.6129 - val_loss: 0.5974\n",
      "Epoch 170/1000\n",
      "0s - loss: 0.6114 - val_loss: 0.5959\n",
      "Epoch 171/1000\n",
      "0s - loss: 0.6101 - val_loss: 0.5944\n",
      "Epoch 172/1000\n",
      "0s - loss: 0.6086 - val_loss: 0.5930\n",
      "Epoch 173/1000\n",
      "0s - loss: 0.6073 - val_loss: 0.5915\n",
      "Epoch 174/1000\n",
      "0s - loss: 0.6060 - val_loss: 0.5900\n",
      "Epoch 175/1000\n",
      "0s - loss: 0.6046 - val_loss: 0.5886\n",
      "Epoch 176/1000\n",
      "0s - loss: 0.6033 - val_loss: 0.5872\n",
      "Epoch 177/1000\n",
      "0s - loss: 0.6020 - val_loss: 0.5858\n",
      "Epoch 178/1000\n",
      "0s - loss: 0.6017 - val_loss: 0.5843\n",
      "Epoch 179/1000\n",
      "0s - loss: 0.5993 - val_loss: 0.5829\n",
      "Epoch 180/1000\n",
      "0s - loss: 0.5983 - val_loss: 0.5818\n",
      "Epoch 181/1000\n",
      "0s - loss: 0.5969 - val_loss: 0.5806\n",
      "Epoch 182/1000\n",
      "0s - loss: 0.5959 - val_loss: 0.5791\n",
      "Epoch 183/1000\n",
      "0s - loss: 0.5943 - val_loss: 0.5778\n",
      "Epoch 184/1000\n",
      "0s - loss: 0.5931 - val_loss: 0.5764\n",
      "Epoch 185/1000\n",
      "0s - loss: 0.5920 - val_loss: 0.5749\n",
      "Epoch 186/1000\n",
      "0s - loss: 0.5907 - val_loss: 0.5736\n",
      "Epoch 187/1000\n",
      "0s - loss: 0.5895 - val_loss: 0.5722\n",
      "Epoch 188/1000\n",
      "0s - loss: 0.5884 - val_loss: 0.5711\n",
      "Epoch 189/1000\n",
      "0s - loss: 0.5871 - val_loss: 0.5697\n",
      "Epoch 190/1000\n",
      "0s - loss: 0.5858 - val_loss: 0.5684\n",
      "Epoch 191/1000\n",
      "0s - loss: 0.5848 - val_loss: 0.5671\n",
      "Epoch 192/1000\n",
      "0s - loss: 0.5835 - val_loss: 0.5658\n",
      "Epoch 193/1000\n",
      "0s - loss: 0.5823 - val_loss: 0.5646\n",
      "Epoch 194/1000\n",
      "0s - loss: 0.5813 - val_loss: 0.5634\n",
      "Epoch 195/1000\n",
      "0s - loss: 0.5801 - val_loss: 0.5623\n",
      "Epoch 196/1000\n",
      "0s - loss: 0.5790 - val_loss: 0.5611\n",
      "Epoch 197/1000\n",
      "0s - loss: 0.5779 - val_loss: 0.5598\n",
      "Epoch 198/1000\n",
      "0s - loss: 0.5768 - val_loss: 0.5585\n",
      "Epoch 199/1000\n",
      "0s - loss: 0.5755 - val_loss: 0.5573\n",
      "Epoch 200/1000\n",
      "0s - loss: 0.5745 - val_loss: 0.5561\n",
      "Epoch 201/1000\n",
      "0s - loss: 0.5735 - val_loss: 0.5549\n",
      "Epoch 202/1000\n",
      "0s - loss: 0.5722 - val_loss: 0.5538\n",
      "Epoch 203/1000\n",
      "0s - loss: 0.5711 - val_loss: 0.5525\n",
      "Epoch 204/1000\n",
      "0s - loss: 0.5700 - val_loss: 0.5513\n",
      "Epoch 205/1000\n",
      "0s - loss: 0.5690 - val_loss: 0.5501\n",
      "Epoch 206/1000\n",
      "0s - loss: 0.5679 - val_loss: 0.5489\n",
      "Epoch 207/1000\n",
      "0s - loss: 0.5669 - val_loss: 0.5478\n",
      "Epoch 208/1000\n",
      "0s - loss: 0.5659 - val_loss: 0.5467\n",
      "Epoch 209/1000\n",
      "0s - loss: 0.5649 - val_loss: 0.5456\n",
      "Epoch 210/1000\n",
      "0s - loss: 0.5638 - val_loss: 0.5445\n",
      "Epoch 211/1000\n",
      "0s - loss: 0.5628 - val_loss: 0.5433\n",
      "Epoch 212/1000\n",
      "0s - loss: 0.5618 - val_loss: 0.5423\n",
      "Epoch 213/1000\n",
      "0s - loss: 0.5609 - val_loss: 0.5412\n",
      "Epoch 214/1000\n",
      "0s - loss: 0.5597 - val_loss: 0.5401\n",
      "Epoch 215/1000\n",
      "0s - loss: 0.5591 - val_loss: 0.5390\n",
      "Epoch 216/1000\n",
      "0s - loss: 0.5577 - val_loss: 0.5380\n",
      "Epoch 217/1000\n",
      "0s - loss: 0.5568 - val_loss: 0.5370\n",
      "Epoch 218/1000\n",
      "0s - loss: 0.5558 - val_loss: 0.5360\n",
      "Epoch 219/1000\n",
      "0s - loss: 0.5549 - val_loss: 0.5349\n",
      "Epoch 220/1000\n",
      "0s - loss: 0.5538 - val_loss: 0.5338\n",
      "Epoch 221/1000\n",
      "0s - loss: 0.5529 - val_loss: 0.5327\n",
      "Epoch 222/1000\n",
      "0s - loss: 0.5519 - val_loss: 0.5316\n",
      "Epoch 223/1000\n",
      "0s - loss: 0.5510 - val_loss: 0.5306\n",
      "Epoch 224/1000\n",
      "0s - loss: 0.5500 - val_loss: 0.5295\n",
      "Epoch 225/1000\n",
      "0s - loss: 0.5492 - val_loss: 0.5286\n",
      "Epoch 226/1000\n",
      "0s - loss: 0.5481 - val_loss: 0.5275\n",
      "Epoch 227/1000\n",
      "0s - loss: 0.5471 - val_loss: 0.5265\n",
      "Epoch 228/1000\n",
      "0s - loss: 0.5467 - val_loss: 0.5254\n",
      "Epoch 229/1000\n",
      "0s - loss: 0.5451 - val_loss: 0.5244\n",
      "Epoch 230/1000\n",
      "0s - loss: 0.5443 - val_loss: 0.5236\n",
      "Epoch 231/1000\n",
      "0s - loss: 0.5437 - val_loss: 0.5227\n",
      "Epoch 232/1000\n",
      "0s - loss: 0.5424 - val_loss: 0.5216\n",
      "Epoch 233/1000\n",
      "0s - loss: 0.5415 - val_loss: 0.5204\n",
      "Epoch 234/1000\n",
      "0s - loss: 0.5412 - val_loss: 0.5193\n",
      "Epoch 235/1000\n",
      "0s - loss: 0.5395 - val_loss: 0.5183\n",
      "Epoch 236/1000\n",
      "0s - loss: 0.5386 - val_loss: 0.5174\n",
      "Epoch 237/1000\n",
      "0s - loss: 0.5379 - val_loss: 0.5165\n",
      "Epoch 238/1000\n",
      "0s - loss: 0.5371 - val_loss: 0.5154\n",
      "Epoch 239/1000\n",
      "0s - loss: 0.5359 - val_loss: 0.5146\n",
      "Epoch 240/1000\n",
      "0s - loss: 0.5351 - val_loss: 0.5136\n",
      "Epoch 241/1000\n",
      "0s - loss: 0.5342 - val_loss: 0.5126\n",
      "Epoch 242/1000\n",
      "0s - loss: 0.5334 - val_loss: 0.5117\n",
      "Epoch 243/1000\n",
      "0s - loss: 0.5324 - val_loss: 0.5106\n",
      "Epoch 244/1000\n",
      "0s - loss: 0.5317 - val_loss: 0.5095\n",
      "Epoch 245/1000\n",
      "0s - loss: 0.5306 - val_loss: 0.5085\n",
      "Epoch 246/1000\n",
      "0s - loss: 0.5297 - val_loss: 0.5076\n",
      "Epoch 247/1000\n",
      "0s - loss: 0.5287 - val_loss: 0.5067\n",
      "Epoch 248/1000\n",
      "0s - loss: 0.5281 - val_loss: 0.5056\n",
      "Epoch 249/1000\n",
      "0s - loss: 0.5270 - val_loss: 0.5047\n",
      "Epoch 250/1000\n",
      "0s - loss: 0.5261 - val_loss: 0.5037\n",
      "Epoch 251/1000\n",
      "0s - loss: 0.5252 - val_loss: 0.5028\n",
      "Epoch 252/1000\n",
      "0s - loss: 0.5248 - val_loss: 0.5019\n",
      "Epoch 253/1000\n",
      "0s - loss: 0.5235 - val_loss: 0.5009\n",
      "Epoch 254/1000\n",
      "0s - loss: 0.5227 - val_loss: 0.4998\n",
      "Epoch 255/1000\n",
      "0s - loss: 0.5217 - val_loss: 0.4989\n",
      "Epoch 256/1000\n",
      "0s - loss: 0.5208 - val_loss: 0.4980\n",
      "Epoch 257/1000\n",
      "0s - loss: 0.5200 - val_loss: 0.4970\n",
      "Epoch 258/1000\n",
      "0s - loss: 0.5190 - val_loss: 0.4961\n",
      "Epoch 259/1000\n",
      "0s - loss: 0.5182 - val_loss: 0.4951\n",
      "Epoch 260/1000\n",
      "0s - loss: 0.5175 - val_loss: 0.4942\n",
      "Epoch 261/1000\n",
      "0s - loss: 0.5165 - val_loss: 0.4933\n",
      "Epoch 262/1000\n",
      "0s - loss: 0.5156 - val_loss: 0.4924\n",
      "Epoch 263/1000\n",
      "0s - loss: 0.5146 - val_loss: 0.4914\n",
      "Epoch 264/1000\n",
      "0s - loss: 0.5138 - val_loss: 0.4904\n",
      "Epoch 265/1000\n",
      "0s - loss: 0.5129 - val_loss: 0.4895\n",
      "Epoch 266/1000\n",
      "0s - loss: 0.5121 - val_loss: 0.4885\n",
      "Epoch 267/1000\n",
      "0s - loss: 0.5112 - val_loss: 0.4876\n",
      "Epoch 268/1000\n",
      "0s - loss: 0.5103 - val_loss: 0.4867\n",
      "Epoch 269/1000\n",
      "0s - loss: 0.5094 - val_loss: 0.4857\n",
      "Epoch 270/1000\n",
      "0s - loss: 0.5086 - val_loss: 0.4848\n",
      "Epoch 271/1000\n",
      "0s - loss: 0.5080 - val_loss: 0.4838\n",
      "Epoch 272/1000\n",
      "0s - loss: 0.5070 - val_loss: 0.4829\n",
      "Epoch 273/1000\n",
      "0s - loss: 0.5060 - val_loss: 0.4820\n",
      "Epoch 274/1000\n",
      "0s - loss: 0.5051 - val_loss: 0.4811\n",
      "Epoch 275/1000\n",
      "0s - loss: 0.5044 - val_loss: 0.4802\n",
      "Epoch 276/1000\n",
      "0s - loss: 0.5035 - val_loss: 0.4793\n",
      "Epoch 277/1000\n",
      "0s - loss: 0.5025 - val_loss: 0.4784\n",
      "Epoch 278/1000\n",
      "0s - loss: 0.5017 - val_loss: 0.4774\n",
      "Epoch 279/1000\n",
      "0s - loss: 0.5008 - val_loss: 0.4765\n",
      "Epoch 280/1000\n",
      "0s - loss: 0.4999 - val_loss: 0.4756\n",
      "Epoch 281/1000\n",
      "0s - loss: 0.4993 - val_loss: 0.4747\n",
      "Epoch 282/1000\n",
      "0s - loss: 0.4983 - val_loss: 0.4737\n",
      "Epoch 283/1000\n",
      "0s - loss: 0.4974 - val_loss: 0.4728\n",
      "Epoch 284/1000\n",
      "0s - loss: 0.4969 - val_loss: 0.4719\n",
      "Epoch 285/1000\n",
      "0s - loss: 0.4957 - val_loss: 0.4710\n",
      "Epoch 286/1000\n",
      "0s - loss: 0.4948 - val_loss: 0.4701\n",
      "Epoch 287/1000\n",
      "0s - loss: 0.4942 - val_loss: 0.4693\n",
      "Epoch 288/1000\n",
      "0s - loss: 0.4932 - val_loss: 0.4683\n",
      "Epoch 289/1000\n",
      "0s - loss: 0.4922 - val_loss: 0.4674\n",
      "Epoch 290/1000\n",
      "0s - loss: 0.4914 - val_loss: 0.4665\n",
      "Epoch 291/1000\n",
      "0s - loss: 0.4908 - val_loss: 0.4655\n",
      "Epoch 292/1000\n",
      "0s - loss: 0.4897 - val_loss: 0.4646\n",
      "Epoch 293/1000\n",
      "0s - loss: 0.4888 - val_loss: 0.4637\n",
      "Epoch 294/1000\n",
      "0s - loss: 0.4880 - val_loss: 0.4628\n",
      "Epoch 295/1000\n",
      "0s - loss: 0.4874 - val_loss: 0.4619\n",
      "Epoch 296/1000\n",
      "0s - loss: 0.4863 - val_loss: 0.4610\n",
      "Epoch 297/1000\n",
      "0s - loss: 0.4857 - val_loss: 0.4601\n",
      "Epoch 298/1000\n",
      "0s - loss: 0.4848 - val_loss: 0.4593\n",
      "Epoch 299/1000\n",
      "0s - loss: 0.4837 - val_loss: 0.4584\n",
      "Epoch 300/1000\n",
      "0s - loss: 0.4828 - val_loss: 0.4575\n",
      "Epoch 301/1000\n",
      "0s - loss: 0.4821 - val_loss: 0.4566\n",
      "Epoch 302/1000\n",
      "0s - loss: 0.4817 - val_loss: 0.4556\n",
      "Epoch 303/1000\n",
      "0s - loss: 0.4803 - val_loss: 0.4547\n",
      "Epoch 304/1000\n",
      "0s - loss: 0.4795 - val_loss: 0.4538\n",
      "Epoch 305/1000\n",
      "0s - loss: 0.4785 - val_loss: 0.4528\n",
      "Epoch 306/1000\n",
      "0s - loss: 0.4777 - val_loss: 0.4519\n",
      "Epoch 307/1000\n",
      "0s - loss: 0.4769 - val_loss: 0.4510\n",
      "Epoch 308/1000\n",
      "0s - loss: 0.4762 - val_loss: 0.4501\n",
      "Epoch 309/1000\n",
      "0s - loss: 0.4751 - val_loss: 0.4492\n",
      "Epoch 310/1000\n",
      "0s - loss: 0.4742 - val_loss: 0.4483\n",
      "Epoch 311/1000\n",
      "0s - loss: 0.4733 - val_loss: 0.4474\n",
      "Epoch 312/1000\n",
      "0s - loss: 0.4725 - val_loss: 0.4465\n",
      "Epoch 313/1000\n",
      "0s - loss: 0.4717 - val_loss: 0.4456\n",
      "Epoch 314/1000\n",
      "0s - loss: 0.4708 - val_loss: 0.4447\n",
      "Epoch 315/1000\n",
      "0s - loss: 0.4702 - val_loss: 0.4438\n",
      "Epoch 316/1000\n",
      "0s - loss: 0.4691 - val_loss: 0.4428\n",
      "Epoch 317/1000\n",
      "0s - loss: 0.4682 - val_loss: 0.4419\n",
      "Epoch 318/1000\n",
      "0s - loss: 0.4677 - val_loss: 0.4411\n",
      "Epoch 319/1000\n",
      "0s - loss: 0.4665 - val_loss: 0.4402\n",
      "Epoch 320/1000\n",
      "0s - loss: 0.4656 - val_loss: 0.4392\n",
      "Epoch 321/1000\n",
      "0s - loss: 0.4648 - val_loss: 0.4383\n",
      "Epoch 322/1000\n",
      "0s - loss: 0.4638 - val_loss: 0.4374\n",
      "Epoch 323/1000\n",
      "0s - loss: 0.4630 - val_loss: 0.4365\n",
      "Epoch 324/1000\n",
      "0s - loss: 0.4623 - val_loss: 0.4356\n",
      "Epoch 325/1000\n",
      "0s - loss: 0.4613 - val_loss: 0.4347\n",
      "Epoch 326/1000\n",
      "0s - loss: 0.4604 - val_loss: 0.4338\n",
      "Epoch 327/1000\n",
      "0s - loss: 0.4597 - val_loss: 0.4330\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.4590 - val_loss: 0.4321\n",
      "Epoch 329/1000\n",
      "0s - loss: 0.4579 - val_loss: 0.4312\n",
      "Epoch 330/1000\n",
      "0s - loss: 0.4570 - val_loss: 0.4302\n",
      "Epoch 331/1000\n",
      "0s - loss: 0.4561 - val_loss: 0.4293\n",
      "Epoch 332/1000\n",
      "0s - loss: 0.4553 - val_loss: 0.4284\n",
      "Epoch 333/1000\n",
      "0s - loss: 0.4543 - val_loss: 0.4275\n",
      "Epoch 334/1000\n",
      "0s - loss: 0.4535 - val_loss: 0.4266\n",
      "Epoch 335/1000\n",
      "0s - loss: 0.4527 - val_loss: 0.4257\n",
      "Epoch 336/1000\n",
      "0s - loss: 0.4520 - val_loss: 0.4248\n",
      "Epoch 337/1000\n",
      "0s - loss: 0.4509 - val_loss: 0.4239\n",
      "Epoch 338/1000\n",
      "0s - loss: 0.4505 - val_loss: 0.4231\n",
      "Epoch 339/1000\n",
      "0s - loss: 0.4495 - val_loss: 0.4222\n",
      "Epoch 340/1000\n",
      "0s - loss: 0.4484 - val_loss: 0.4213\n",
      "Epoch 341/1000\n",
      "0s - loss: 0.4475 - val_loss: 0.4205\n",
      "Epoch 342/1000\n",
      "0s - loss: 0.4467 - val_loss: 0.4196\n",
      "Epoch 343/1000\n",
      "0s - loss: 0.4458 - val_loss: 0.4187\n",
      "Epoch 344/1000\n",
      "0s - loss: 0.4448 - val_loss: 0.4178\n",
      "Epoch 345/1000\n",
      "0s - loss: 0.4441 - val_loss: 0.4170\n",
      "Epoch 346/1000\n",
      "0s - loss: 0.4431 - val_loss: 0.4161\n",
      "Epoch 347/1000\n",
      "0s - loss: 0.4422 - val_loss: 0.4152\n",
      "Epoch 348/1000\n",
      "0s - loss: 0.4414 - val_loss: 0.4143\n",
      "Epoch 349/1000\n",
      "0s - loss: 0.4406 - val_loss: 0.4134\n",
      "Epoch 350/1000\n",
      "0s - loss: 0.4397 - val_loss: 0.4125\n",
      "Epoch 351/1000\n",
      "0s - loss: 0.4388 - val_loss: 0.4116\n",
      "Epoch 352/1000\n",
      "0s - loss: 0.4380 - val_loss: 0.4106\n",
      "Epoch 353/1000\n",
      "0s - loss: 0.4372 - val_loss: 0.4097\n",
      "Epoch 354/1000\n",
      "0s - loss: 0.4364 - val_loss: 0.4088\n",
      "Epoch 355/1000\n",
      "0s - loss: 0.4356 - val_loss: 0.4079\n",
      "Epoch 356/1000\n",
      "0s - loss: 0.4345 - val_loss: 0.4070\n",
      "Epoch 357/1000\n",
      "0s - loss: 0.4336 - val_loss: 0.4062\n",
      "Epoch 358/1000\n",
      "0s - loss: 0.4327 - val_loss: 0.4053\n",
      "Epoch 359/1000\n",
      "0s - loss: 0.4319 - val_loss: 0.4045\n",
      "Epoch 360/1000\n",
      "0s - loss: 0.4311 - val_loss: 0.4036\n",
      "Epoch 361/1000\n",
      "0s - loss: 0.4307 - val_loss: 0.4028\n",
      "Epoch 362/1000\n",
      "0s - loss: 0.4298 - val_loss: 0.4017\n",
      "Epoch 363/1000\n",
      "0s - loss: 0.4285 - val_loss: 0.4007\n",
      "Epoch 364/1000\n",
      "0s - loss: 0.4276 - val_loss: 0.3998\n",
      "Epoch 365/1000\n",
      "0s - loss: 0.4269 - val_loss: 0.3990\n",
      "Epoch 366/1000\n",
      "0s - loss: 0.4260 - val_loss: 0.3981\n",
      "Epoch 367/1000\n",
      "0s - loss: 0.4250 - val_loss: 0.3972\n",
      "Epoch 368/1000\n",
      "0s - loss: 0.4242 - val_loss: 0.3963\n",
      "Epoch 369/1000\n",
      "0s - loss: 0.4235 - val_loss: 0.3955\n",
      "Epoch 370/1000\n",
      "0s - loss: 0.4226 - val_loss: 0.3946\n",
      "Epoch 371/1000\n",
      "0s - loss: 0.4216 - val_loss: 0.3937\n",
      "Epoch 372/1000\n",
      "0s - loss: 0.4208 - val_loss: 0.3928\n",
      "Epoch 373/1000\n",
      "0s - loss: 0.4202 - val_loss: 0.3920\n",
      "Epoch 374/1000\n",
      "0s - loss: 0.4194 - val_loss: 0.3911\n",
      "Epoch 375/1000\n",
      "0s - loss: 0.4184 - val_loss: 0.3903\n",
      "Epoch 376/1000\n",
      "0s - loss: 0.4175 - val_loss: 0.3895\n",
      "Epoch 377/1000\n",
      "0s - loss: 0.4166 - val_loss: 0.3886\n",
      "Epoch 378/1000\n",
      "0s - loss: 0.4159 - val_loss: 0.3878\n",
      "Epoch 379/1000\n",
      "0s - loss: 0.4148 - val_loss: 0.3870\n",
      "Epoch 380/1000\n",
      "0s - loss: 0.4142 - val_loss: 0.3863\n",
      "Epoch 381/1000\n",
      "0s - loss: 0.4133 - val_loss: 0.3853\n",
      "Epoch 382/1000\n",
      "0s - loss: 0.4125 - val_loss: 0.3843\n",
      "Epoch 383/1000\n",
      "0s - loss: 0.4121 - val_loss: 0.3835\n",
      "Epoch 384/1000\n",
      "0s - loss: 0.4108 - val_loss: 0.3826\n",
      "Epoch 385/1000\n",
      "0s - loss: 0.4099 - val_loss: 0.3815\n",
      "Epoch 386/1000\n",
      "0s - loss: 0.4098 - val_loss: 0.3807\n",
      "Epoch 387/1000\n",
      "0s - loss: 0.4082 - val_loss: 0.3799\n",
      "Epoch 388/1000\n",
      "0s - loss: 0.4073 - val_loss: 0.3791\n",
      "Epoch 389/1000\n",
      "0s - loss: 0.4069 - val_loss: 0.3787\n",
      "Epoch 390/1000\n",
      "0s - loss: 0.4062 - val_loss: 0.3779\n",
      "Epoch 391/1000\n",
      "0s - loss: 0.4050 - val_loss: 0.3766\n",
      "Epoch 392/1000\n",
      "0s - loss: 0.4044 - val_loss: 0.3756\n",
      "Epoch 393/1000\n",
      "0s - loss: 0.4034 - val_loss: 0.3747\n",
      "Epoch 394/1000\n",
      "0s - loss: 0.4026 - val_loss: 0.3740\n",
      "Epoch 395/1000\n",
      "0s - loss: 0.4016 - val_loss: 0.3732\n",
      "Epoch 396/1000\n",
      "0s - loss: 0.4012 - val_loss: 0.3725\n",
      "Epoch 397/1000\n",
      "0s - loss: 0.4000 - val_loss: 0.3715\n",
      "Epoch 398/1000\n",
      "0s - loss: 0.3993 - val_loss: 0.3706\n",
      "Epoch 399/1000\n",
      "0s - loss: 0.3986 - val_loss: 0.3698\n",
      "Epoch 400/1000\n",
      "0s - loss: 0.3977 - val_loss: 0.3691\n",
      "Epoch 401/1000\n",
      "0s - loss: 0.3972 - val_loss: 0.3684\n",
      "Epoch 402/1000\n",
      "0s - loss: 0.3960 - val_loss: 0.3675\n",
      "Epoch 403/1000\n",
      "0s - loss: 0.3956 - val_loss: 0.3665\n",
      "Epoch 404/1000\n",
      "0s - loss: 0.3949 - val_loss: 0.3659\n",
      "Epoch 405/1000\n",
      "0s - loss: 0.3937 - val_loss: 0.3650\n",
      "Epoch 406/1000\n",
      "0s - loss: 0.3930 - val_loss: 0.3644\n",
      "Epoch 407/1000\n",
      "0s - loss: 0.3921 - val_loss: 0.3636\n",
      "Epoch 408/1000\n",
      "0s - loss: 0.3913 - val_loss: 0.3628\n",
      "Epoch 409/1000\n",
      "0s - loss: 0.3906 - val_loss: 0.3619\n",
      "Epoch 410/1000\n",
      "0s - loss: 0.3898 - val_loss: 0.3613\n",
      "Epoch 411/1000\n",
      "0s - loss: 0.3891 - val_loss: 0.3605\n",
      "Epoch 412/1000\n",
      "0s - loss: 0.3888 - val_loss: 0.3596\n",
      "Epoch 413/1000\n",
      "0s - loss: 0.3876 - val_loss: 0.3589\n",
      "Epoch 414/1000\n",
      "0s - loss: 0.3869 - val_loss: 0.3581\n",
      "Epoch 415/1000\n",
      "0s - loss: 0.3858 - val_loss: 0.3574\n",
      "Epoch 416/1000\n",
      "0s - loss: 0.3854 - val_loss: 0.3568\n",
      "Epoch 417/1000\n",
      "0s - loss: 0.3845 - val_loss: 0.3563\n",
      "Epoch 418/1000\n",
      "0s - loss: 0.3837 - val_loss: 0.3554\n",
      "Epoch 419/1000\n",
      "0s - loss: 0.3828 - val_loss: 0.3543\n",
      "Epoch 420/1000\n",
      "0s - loss: 0.3822 - val_loss: 0.3532\n",
      "Epoch 421/1000\n",
      "0s - loss: 0.3816 - val_loss: 0.3523\n",
      "Epoch 422/1000\n",
      "0s - loss: 0.3805 - val_loss: 0.3517\n",
      "Epoch 423/1000\n",
      "0s - loss: 0.3797 - val_loss: 0.3511\n",
      "Epoch 424/1000\n",
      "0s - loss: 0.3790 - val_loss: 0.3505\n",
      "Epoch 425/1000\n",
      "0s - loss: 0.3784 - val_loss: 0.3500\n",
      "Epoch 426/1000\n",
      "0s - loss: 0.3777 - val_loss: 0.3493\n",
      "Epoch 427/1000\n",
      "0s - loss: 0.3769 - val_loss: 0.3483\n",
      "Epoch 428/1000\n",
      "0s - loss: 0.3760 - val_loss: 0.3473\n",
      "Epoch 429/1000\n",
      "0s - loss: 0.3754 - val_loss: 0.3463\n",
      "Epoch 430/1000\n",
      "0s - loss: 0.3745 - val_loss: 0.3455\n",
      "Epoch 431/1000\n",
      "0s - loss: 0.3742 - val_loss: 0.3448\n",
      "Epoch 432/1000\n",
      "0s - loss: 0.3732 - val_loss: 0.3438\n",
      "Epoch 433/1000\n",
      "0s - loss: 0.3726 - val_loss: 0.3431\n",
      "Epoch 434/1000\n",
      "0s - loss: 0.3721 - val_loss: 0.3424\n",
      "Epoch 435/1000\n",
      "0s - loss: 0.3712 - val_loss: 0.3419\n",
      "Epoch 436/1000\n",
      "0s - loss: 0.3704 - val_loss: 0.3411\n",
      "Epoch 437/1000\n",
      "0s - loss: 0.3694 - val_loss: 0.3405\n",
      "Epoch 438/1000\n",
      "0s - loss: 0.3689 - val_loss: 0.3401\n",
      "Epoch 439/1000\n",
      "0s - loss: 0.3681 - val_loss: 0.3396\n",
      "Epoch 440/1000\n",
      "0s - loss: 0.3675 - val_loss: 0.3388\n",
      "Epoch 441/1000\n",
      "0s - loss: 0.3665 - val_loss: 0.3376\n",
      "Epoch 442/1000\n",
      "0s - loss: 0.3660 - val_loss: 0.3365\n",
      "Epoch 443/1000\n",
      "0s - loss: 0.3652 - val_loss: 0.3358\n",
      "Epoch 444/1000\n",
      "0s - loss: 0.3650 - val_loss: 0.3355\n",
      "Epoch 445/1000\n",
      "0s - loss: 0.3638 - val_loss: 0.3348\n",
      "Epoch 446/1000\n",
      "0s - loss: 0.3634 - val_loss: 0.3339\n",
      "Epoch 447/1000\n",
      "0s - loss: 0.3627 - val_loss: 0.3336\n",
      "Epoch 448/1000\n",
      "0s - loss: 0.3617 - val_loss: 0.3328\n",
      "Epoch 449/1000\n",
      "0s - loss: 0.3611 - val_loss: 0.3320\n",
      "Epoch 450/1000\n",
      "0s - loss: 0.3603 - val_loss: 0.3312\n",
      "Epoch 451/1000\n",
      "0s - loss: 0.3597 - val_loss: 0.3307\n",
      "Epoch 452/1000\n",
      "0s - loss: 0.3589 - val_loss: 0.3297\n",
      "Epoch 453/1000\n",
      "0s - loss: 0.3583 - val_loss: 0.3288\n",
      "Epoch 454/1000\n",
      "0s - loss: 0.3577 - val_loss: 0.3282\n",
      "Epoch 455/1000\n",
      "0s - loss: 0.3572 - val_loss: 0.3278\n",
      "Epoch 456/1000\n",
      "0s - loss: 0.3562 - val_loss: 0.3270\n",
      "Epoch 457/1000\n",
      "0s - loss: 0.3562 - val_loss: 0.3266\n",
      "Epoch 458/1000\n",
      "0s - loss: 0.3549 - val_loss: 0.3255\n",
      "Epoch 459/1000\n",
      "0s - loss: 0.3544 - val_loss: 0.3247\n",
      "Epoch 460/1000\n",
      "0s - loss: 0.3536 - val_loss: 0.3242\n",
      "Epoch 461/1000\n",
      "0s - loss: 0.3529 - val_loss: 0.3236\n",
      "Epoch 462/1000\n",
      "0s - loss: 0.3522 - val_loss: 0.3230\n",
      "Epoch 463/1000\n",
      "0s - loss: 0.3516 - val_loss: 0.3223\n",
      "Epoch 464/1000\n",
      "0s - loss: 0.3509 - val_loss: 0.3217\n",
      "Epoch 465/1000\n",
      "0s - loss: 0.3503 - val_loss: 0.3212\n",
      "Epoch 466/1000\n",
      "0s - loss: 0.3495 - val_loss: 0.3204\n",
      "Epoch 467/1000\n",
      "0s - loss: 0.3489 - val_loss: 0.3195\n",
      "Epoch 468/1000\n",
      "0s - loss: 0.3484 - val_loss: 0.3185\n",
      "Epoch 469/1000\n",
      "0s - loss: 0.3476 - val_loss: 0.3180\n",
      "Epoch 470/1000\n",
      "0s - loss: 0.3471 - val_loss: 0.3176\n",
      "Epoch 471/1000\n",
      "0s - loss: 0.3463 - val_loss: 0.3169\n",
      "Epoch 472/1000\n",
      "0s - loss: 0.3456 - val_loss: 0.3163\n",
      "Epoch 473/1000\n",
      "0s - loss: 0.3450 - val_loss: 0.3158\n",
      "Epoch 474/1000\n",
      "0s - loss: 0.3451 - val_loss: 0.3148\n",
      "Epoch 475/1000\n",
      "0s - loss: 0.3441 - val_loss: 0.3150\n",
      "Epoch 476/1000\n",
      "0s - loss: 0.3435 - val_loss: 0.3140\n",
      "Epoch 477/1000\n",
      "0s - loss: 0.3425 - val_loss: 0.3135\n",
      "Epoch 478/1000\n",
      "0s - loss: 0.3420 - val_loss: 0.3126\n",
      "Epoch 479/1000\n",
      "0s - loss: 0.3412 - val_loss: 0.3121\n",
      "Epoch 480/1000\n",
      "0s - loss: 0.3412 - val_loss: 0.3118\n",
      "Epoch 481/1000\n",
      "0s - loss: 0.3409 - val_loss: 0.3102\n",
      "Epoch 482/1000\n",
      "0s - loss: 0.3397 - val_loss: 0.3095\n",
      "Epoch 483/1000\n",
      "0s - loss: 0.3390 - val_loss: 0.3096\n",
      "Epoch 484/1000\n",
      "0s - loss: 0.3383 - val_loss: 0.3092\n",
      "Epoch 485/1000\n",
      "0s - loss: 0.3376 - val_loss: 0.3082\n",
      "Epoch 486/1000\n",
      "0s - loss: 0.3369 - val_loss: 0.3074\n",
      "Epoch 487/1000\n",
      "0s - loss: 0.3364 - val_loss: 0.3067\n",
      "Epoch 488/1000\n",
      "0s - loss: 0.3358 - val_loss: 0.3060\n",
      "Epoch 489/1000\n",
      "0s - loss: 0.3351 - val_loss: 0.3055\n",
      "Epoch 490/1000\n",
      "0s - loss: 0.3349 - val_loss: 0.3054\n",
      "Epoch 491/1000\n",
      "0s - loss: 0.3341 - val_loss: 0.3044\n",
      "Epoch 492/1000\n",
      "0s - loss: 0.3333 - val_loss: 0.3039\n",
      "Epoch 493/1000\n",
      "0s - loss: 0.3326 - val_loss: 0.3033\n",
      "Epoch 494/1000\n",
      "0s - loss: 0.3322 - val_loss: 0.3028\n",
      "Epoch 495/1000\n",
      "0s - loss: 0.3316 - val_loss: 0.3022\n",
      "Epoch 496/1000\n",
      "0s - loss: 0.3308 - val_loss: 0.3013\n",
      "Epoch 497/1000\n",
      "0s - loss: 0.3305 - val_loss: 0.3004\n",
      "Epoch 498/1000\n",
      "0s - loss: 0.3299 - val_loss: 0.3001\n",
      "Epoch 499/1000\n",
      "0s - loss: 0.3294 - val_loss: 0.2995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000\n",
      "0s - loss: 0.3286 - val_loss: 0.2994\n",
      "Epoch 501/1000\n",
      "0s - loss: 0.3280 - val_loss: 0.2991\n",
      "Epoch 502/1000\n",
      "0s - loss: 0.3274 - val_loss: 0.2982\n",
      "Epoch 503/1000\n",
      "0s - loss: 0.3274 - val_loss: 0.2981\n",
      "Epoch 504/1000\n",
      "0s - loss: 0.3265 - val_loss: 0.2969\n",
      "Epoch 505/1000\n",
      "0s - loss: 0.3258 - val_loss: 0.2961\n",
      "Epoch 506/1000\n",
      "0s - loss: 0.3253 - val_loss: 0.2955\n",
      "Epoch 507/1000\n",
      "0s - loss: 0.3247 - val_loss: 0.2951\n",
      "Epoch 508/1000\n",
      "0s - loss: 0.3240 - val_loss: 0.2942\n",
      "Epoch 509/1000\n",
      "0s - loss: 0.3234 - val_loss: 0.2935\n",
      "Epoch 510/1000\n",
      "0s - loss: 0.3230 - val_loss: 0.2931\n",
      "Epoch 511/1000\n",
      "0s - loss: 0.3225 - val_loss: 0.2923\n",
      "Epoch 512/1000\n",
      "0s - loss: 0.3218 - val_loss: 0.2920\n",
      "Epoch 513/1000\n",
      "0s - loss: 0.3214 - val_loss: 0.2917\n",
      "Epoch 514/1000\n",
      "0s - loss: 0.3208 - val_loss: 0.2910\n",
      "Epoch 515/1000\n",
      "0s - loss: 0.3200 - val_loss: 0.2902\n",
      "Epoch 516/1000\n",
      "0s - loss: 0.3195 - val_loss: 0.2895\n",
      "Epoch 517/1000\n",
      "0s - loss: 0.3193 - val_loss: 0.2896\n",
      "Epoch 518/1000\n",
      "0s - loss: 0.3186 - val_loss: 0.2889\n",
      "Epoch 519/1000\n",
      "0s - loss: 0.3179 - val_loss: 0.2880\n",
      "Epoch 520/1000\n",
      "0s - loss: 0.3175 - val_loss: 0.2877\n",
      "Epoch 521/1000\n",
      "0s - loss: 0.3168 - val_loss: 0.2870\n",
      "Epoch 522/1000\n",
      "0s - loss: 0.3163 - val_loss: 0.2866\n",
      "Epoch 523/1000\n",
      "0s - loss: 0.3157 - val_loss: 0.2861\n",
      "Epoch 524/1000\n",
      "0s - loss: 0.3151 - val_loss: 0.2857\n",
      "Epoch 525/1000\n",
      "0s - loss: 0.3147 - val_loss: 0.2850\n",
      "Epoch 526/1000\n",
      "0s - loss: 0.3143 - val_loss: 0.2849\n",
      "Epoch 527/1000\n",
      "0s - loss: 0.3136 - val_loss: 0.2842\n",
      "Epoch 528/1000\n",
      "0s - loss: 0.3130 - val_loss: 0.2836\n",
      "Epoch 529/1000\n",
      "0s - loss: 0.3125 - val_loss: 0.2829\n",
      "Epoch 530/1000\n",
      "0s - loss: 0.3122 - val_loss: 0.2820\n",
      "Epoch 531/1000\n",
      "0s - loss: 0.3116 - val_loss: 0.2815\n",
      "Epoch 532/1000\n",
      "0s - loss: 0.3110 - val_loss: 0.2819\n",
      "Epoch 533/1000\n",
      "0s - loss: 0.3106 - val_loss: 0.2817\n",
      "Epoch 534/1000\n",
      "0s - loss: 0.3099 - val_loss: 0.2805\n",
      "Epoch 535/1000\n",
      "0s - loss: 0.3095 - val_loss: 0.2797\n",
      "Epoch 536/1000\n",
      "0s - loss: 0.3089 - val_loss: 0.2786\n",
      "Epoch 537/1000\n",
      "0s - loss: 0.3086 - val_loss: 0.2781\n",
      "Epoch 538/1000\n",
      "0s - loss: 0.3079 - val_loss: 0.2778\n",
      "Epoch 539/1000\n",
      "0s - loss: 0.3075 - val_loss: 0.2778\n",
      "Epoch 540/1000\n",
      "0s - loss: 0.3068 - val_loss: 0.2773\n",
      "Epoch 541/1000\n",
      "0s - loss: 0.3065 - val_loss: 0.2766\n",
      "Epoch 542/1000\n",
      "0s - loss: 0.3061 - val_loss: 0.2766\n",
      "Epoch 543/1000\n",
      "0s - loss: 0.3054 - val_loss: 0.2758\n",
      "Epoch 544/1000\n",
      "0s - loss: 0.3060 - val_loss: 0.2743\n",
      "Epoch 545/1000\n",
      "0s - loss: 0.3045 - val_loss: 0.2740\n",
      "Epoch 546/1000\n",
      "0s - loss: 0.3039 - val_loss: 0.2738\n",
      "Epoch 547/1000\n",
      "0s - loss: 0.3033 - val_loss: 0.2737\n",
      "Epoch 548/1000\n",
      "0s - loss: 0.3030 - val_loss: 0.2736\n",
      "Epoch 549/1000\n",
      "0s - loss: 0.3024 - val_loss: 0.2727\n",
      "Epoch 550/1000\n",
      "0s - loss: 0.3018 - val_loss: 0.2720\n",
      "Epoch 551/1000\n",
      "0s - loss: 0.3014 - val_loss: 0.2714\n",
      "Epoch 552/1000\n",
      "0s - loss: 0.3010 - val_loss: 0.2706\n",
      "Epoch 553/1000\n",
      "0s - loss: 0.3005 - val_loss: 0.2702\n",
      "Epoch 554/1000\n",
      "0s - loss: 0.2999 - val_loss: 0.2704\n",
      "Epoch 555/1000\n",
      "0s - loss: 0.2995 - val_loss: 0.2704\n",
      "Epoch 556/1000\n",
      "0s - loss: 0.2992 - val_loss: 0.2698\n",
      "Epoch 557/1000\n",
      "0s - loss: 0.2985 - val_loss: 0.2686\n",
      "Epoch 558/1000\n",
      "0s - loss: 0.2980 - val_loss: 0.2679\n",
      "Epoch 559/1000\n",
      "0s - loss: 0.2976 - val_loss: 0.2675\n",
      "Epoch 560/1000\n",
      "0s - loss: 0.2973 - val_loss: 0.2673\n",
      "Epoch 561/1000\n",
      "0s - loss: 0.2966 - val_loss: 0.2664\n",
      "Epoch 562/1000\n",
      "0s - loss: 0.2962 - val_loss: 0.2662\n",
      "Epoch 563/1000\n",
      "0s - loss: 0.2958 - val_loss: 0.2660\n",
      "Epoch 564/1000\n",
      "0s - loss: 0.2952 - val_loss: 0.2648\n",
      "Epoch 565/1000\n",
      "0s - loss: 0.2948 - val_loss: 0.2646\n",
      "Epoch 566/1000\n",
      "0s - loss: 0.2946 - val_loss: 0.2639\n",
      "Epoch 567/1000\n",
      "0s - loss: 0.2941 - val_loss: 0.2636\n",
      "Epoch 568/1000\n",
      "0s - loss: 0.2932 - val_loss: 0.2637\n",
      "Epoch 569/1000\n",
      "0s - loss: 0.2931 - val_loss: 0.2643\n",
      "Epoch 570/1000\n",
      "0s - loss: 0.2924 - val_loss: 0.2634\n",
      "Epoch 571/1000\n",
      "0s - loss: 0.2921 - val_loss: 0.2629\n",
      "Epoch 572/1000\n",
      "0s - loss: 0.2912 - val_loss: 0.2615\n",
      "Epoch 573/1000\n",
      "0s - loss: 0.2912 - val_loss: 0.2604\n",
      "Epoch 574/1000\n",
      "0s - loss: 0.2909 - val_loss: 0.2604\n",
      "Epoch 575/1000\n",
      "0s - loss: 0.2900 - val_loss: 0.2602\n",
      "Epoch 576/1000\n",
      "0s - loss: 0.2898 - val_loss: 0.2604\n",
      "Epoch 577/1000\n",
      "0s - loss: 0.2893 - val_loss: 0.2601\n",
      "Epoch 578/1000\n",
      "0s - loss: 0.2890 - val_loss: 0.2590\n",
      "Epoch 579/1000\n",
      "0s - loss: 0.2882 - val_loss: 0.2585\n",
      "Epoch 580/1000\n",
      "0s - loss: 0.2877 - val_loss: 0.2578\n",
      "Epoch 581/1000\n",
      "0s - loss: 0.2874 - val_loss: 0.2576\n",
      "Epoch 582/1000\n",
      "0s - loss: 0.2868 - val_loss: 0.2571\n",
      "Epoch 583/1000\n",
      "0s - loss: 0.2864 - val_loss: 0.2564\n",
      "Epoch 584/1000\n",
      "0s - loss: 0.2859 - val_loss: 0.2558\n",
      "Epoch 585/1000\n",
      "0s - loss: 0.2856 - val_loss: 0.2553\n",
      "Epoch 586/1000\n",
      "0s - loss: 0.2856 - val_loss: 0.2547\n",
      "Epoch 587/1000\n",
      "0s - loss: 0.2845 - val_loss: 0.2549\n",
      "Epoch 588/1000\n",
      "0s - loss: 0.2843 - val_loss: 0.2550\n",
      "Epoch 589/1000\n",
      "0s - loss: 0.2839 - val_loss: 0.2546\n",
      "Epoch 590/1000\n",
      "0s - loss: 0.2832 - val_loss: 0.2537\n",
      "Epoch 591/1000\n",
      "0s - loss: 0.2828 - val_loss: 0.2531\n",
      "Epoch 592/1000\n",
      "0s - loss: 0.2826 - val_loss: 0.2521\n",
      "Epoch 593/1000\n",
      "0s - loss: 0.2820 - val_loss: 0.2517\n",
      "Epoch 594/1000\n",
      "0s - loss: 0.2817 - val_loss: 0.2518\n",
      "Epoch 595/1000\n",
      "0s - loss: 0.2816 - val_loss: 0.2522\n",
      "Epoch 596/1000\n",
      "0s - loss: 0.2809 - val_loss: 0.2515\n",
      "Epoch 597/1000\n",
      "0s - loss: 0.2805 - val_loss: 0.2510\n",
      "Epoch 598/1000\n",
      "0s - loss: 0.2803 - val_loss: 0.2493\n",
      "Epoch 599/1000\n",
      "0s - loss: 0.2797 - val_loss: 0.2493\n",
      "Epoch 600/1000\n",
      "0s - loss: 0.2791 - val_loss: 0.2488\n",
      "Epoch 601/1000\n",
      "0s - loss: 0.2787 - val_loss: 0.2483\n",
      "Epoch 602/1000\n",
      "0s - loss: 0.2782 - val_loss: 0.2478\n",
      "Epoch 603/1000\n",
      "0s - loss: 0.2777 - val_loss: 0.2479\n",
      "Epoch 604/1000\n",
      "0s - loss: 0.2773 - val_loss: 0.2481\n",
      "Epoch 605/1000\n",
      "0s - loss: 0.2776 - val_loss: 0.2485\n",
      "Epoch 606/1000\n",
      "0s - loss: 0.2768 - val_loss: 0.2468\n",
      "Epoch 607/1000\n",
      "0s - loss: 0.2760 - val_loss: 0.2461\n",
      "Epoch 608/1000\n",
      "0s - loss: 0.2762 - val_loss: 0.2450\n",
      "Epoch 609/1000\n",
      "0s - loss: 0.2753 - val_loss: 0.2451\n",
      "Epoch 610/1000\n",
      "0s - loss: 0.2748 - val_loss: 0.2451\n",
      "Epoch 611/1000\n",
      "0s - loss: 0.2746 - val_loss: 0.2447\n",
      "Epoch 612/1000\n",
      "0s - loss: 0.2739 - val_loss: 0.2444\n",
      "Epoch 613/1000\n",
      "0s - loss: 0.2737 - val_loss: 0.2443\n",
      "Epoch 614/1000\n",
      "0s - loss: 0.2734 - val_loss: 0.2434\n",
      "Epoch 615/1000\n",
      "0s - loss: 0.2728 - val_loss: 0.2432\n",
      "Epoch 616/1000\n",
      "0s - loss: 0.2724 - val_loss: 0.2428\n",
      "Epoch 617/1000\n",
      "0s - loss: 0.2723 - val_loss: 0.2417\n",
      "Epoch 618/1000\n",
      "0s - loss: 0.2719 - val_loss: 0.2414\n",
      "Epoch 619/1000\n",
      "0s - loss: 0.2712 - val_loss: 0.2412\n",
      "Epoch 620/1000\n",
      "0s - loss: 0.2707 - val_loss: 0.2415\n",
      "Epoch 621/1000\n",
      "0s - loss: 0.2704 - val_loss: 0.2410\n",
      "Epoch 622/1000\n",
      "0s - loss: 0.2701 - val_loss: 0.2405\n",
      "Epoch 623/1000\n",
      "0s - loss: 0.2698 - val_loss: 0.2408\n",
      "Epoch 624/1000\n",
      "0s - loss: 0.2694 - val_loss: 0.2399\n",
      "Epoch 625/1000\n",
      "0s - loss: 0.2688 - val_loss: 0.2391\n",
      "Epoch 626/1000\n",
      "0s - loss: 0.2684 - val_loss: 0.2385\n",
      "Epoch 627/1000\n",
      "0s - loss: 0.2680 - val_loss: 0.2380\n",
      "Epoch 628/1000\n",
      "0s - loss: 0.2675 - val_loss: 0.2380\n",
      "Epoch 629/1000\n",
      "0s - loss: 0.2673 - val_loss: 0.2380\n",
      "Epoch 630/1000\n",
      "0s - loss: 0.2671 - val_loss: 0.2371\n",
      "Epoch 631/1000\n",
      "0s - loss: 0.2668 - val_loss: 0.2365\n",
      "Epoch 632/1000\n",
      "0s - loss: 0.2661 - val_loss: 0.2373\n",
      "Epoch 633/1000\n",
      "0s - loss: 0.2660 - val_loss: 0.2372\n",
      "Epoch 634/1000\n",
      "0s - loss: 0.2654 - val_loss: 0.2365\n",
      "Epoch 635/1000\n",
      "0s - loss: 0.2649 - val_loss: 0.2355\n",
      "Epoch 636/1000\n",
      "0s - loss: 0.2645 - val_loss: 0.2349\n",
      "Epoch 637/1000\n",
      "0s - loss: 0.2641 - val_loss: 0.2344\n",
      "Epoch 638/1000\n",
      "0s - loss: 0.2640 - val_loss: 0.2341\n",
      "Epoch 639/1000\n",
      "0s - loss: 0.2642 - val_loss: 0.2328\n",
      "Epoch 640/1000\n",
      "0s - loss: 0.2634 - val_loss: 0.2335\n",
      "Epoch 641/1000\n",
      "0s - loss: 0.2627 - val_loss: 0.2330\n",
      "Epoch 642/1000\n",
      "0s - loss: 0.2628 - val_loss: 0.2333\n",
      "Epoch 643/1000\n",
      "0s - loss: 0.2619 - val_loss: 0.2323\n",
      "Epoch 644/1000\n",
      "0s - loss: 0.2614 - val_loss: 0.2311\n",
      "Epoch 645/1000\n",
      "0s - loss: 0.2611 - val_loss: 0.2307\n",
      "Epoch 646/1000\n",
      "0s - loss: 0.2611 - val_loss: 0.2300\n",
      "Epoch 647/1000\n",
      "0s - loss: 0.2604 - val_loss: 0.2298\n",
      "Epoch 648/1000\n",
      "0s - loss: 0.2600 - val_loss: 0.2304\n",
      "Epoch 649/1000\n",
      "0s - loss: 0.2598 - val_loss: 0.2299\n",
      "Epoch 650/1000\n",
      "0s - loss: 0.2592 - val_loss: 0.2300\n",
      "Epoch 651/1000\n",
      "0s - loss: 0.2590 - val_loss: 0.2304\n",
      "Epoch 652/1000\n",
      "0s - loss: 0.2587 - val_loss: 0.2300\n",
      "Epoch 00651: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1696204d780>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "species = encode_text_index(df,\"species\")\n",
    "x,y = to_xy(df,\"species\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "monitor=EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor], verbose=2, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.30893914e-04   6.72661245e-01   3.26807767e-01]\n",
      " [  8.60727847e-01   1.30020529e-01   9.25159082e-03]\n",
      " [  1.64551397e-14   2.38246135e-02   9.76175368e-01]\n",
      " [  5.03026204e-05   5.64165950e-01   4.35783744e-01]\n",
      " [  1.96652749e-04   6.28245175e-01   3.71558130e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "print(pred[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 38 samples\n",
      "Epoch 1/1000\n",
      "0s - loss: 1.5972 - val_loss: 1.7079\n",
      "Epoch 2/1000\n",
      "0s - loss: 1.5224 - val_loss: 1.6254\n",
      "Epoch 3/1000\n",
      "0s - loss: 1.4554 - val_loss: 1.5480\n",
      "Epoch 4/1000\n",
      "0s - loss: 1.3990 - val_loss: 1.4814\n",
      "Epoch 5/1000\n",
      "0s - loss: 1.3444 - val_loss: 1.4283\n",
      "Epoch 6/1000\n",
      "0s - loss: 1.3009 - val_loss: 1.3805\n",
      "Epoch 7/1000\n",
      "0s - loss: 1.2612 - val_loss: 1.3370\n",
      "Epoch 8/1000\n",
      "0s - loss: 1.2273 - val_loss: 1.2962\n",
      "Epoch 9/1000\n",
      "0s - loss: 1.1947 - val_loss: 1.2596\n",
      "Epoch 10/1000\n",
      "0s - loss: 1.1650 - val_loss: 1.2258\n",
      "Epoch 11/1000\n",
      "0s - loss: 1.1373 - val_loss: 1.1949\n",
      "Epoch 12/1000\n",
      "0s - loss: 1.1137 - val_loss: 1.1658\n",
      "Epoch 13/1000\n",
      "0s - loss: 1.0901 - val_loss: 1.1393\n",
      "Epoch 14/1000\n",
      "0s - loss: 1.0685 - val_loss: 1.1159\n",
      "Epoch 15/1000\n",
      "0s - loss: 1.0503 - val_loss: 1.0941\n",
      "Epoch 16/1000\n",
      "0s - loss: 1.0320 - val_loss: 1.0740\n",
      "Epoch 17/1000\n",
      "0s - loss: 1.0170 - val_loss: 1.0553\n",
      "Epoch 18/1000\n",
      "0s - loss: 1.0025 - val_loss: 1.0368\n",
      "Epoch 19/1000\n",
      "0s - loss: 0.9870 - val_loss: 1.0201\n",
      "Epoch 20/1000\n",
      "0s - loss: 0.9737 - val_loss: 1.0049\n",
      "Epoch 21/1000\n",
      "0s - loss: 0.9611 - val_loss: 0.9910\n",
      "Epoch 22/1000\n",
      "0s - loss: 0.9490 - val_loss: 0.9775\n",
      "Epoch 23/1000\n",
      "0s - loss: 0.9378 - val_loss: 0.9638\n",
      "Epoch 24/1000\n",
      "0s - loss: 0.9270 - val_loss: 0.9508\n",
      "Epoch 25/1000\n",
      "0s - loss: 0.9159 - val_loss: 0.9384\n",
      "Epoch 26/1000\n",
      "0s - loss: 0.9064 - val_loss: 0.9262\n",
      "Epoch 27/1000\n",
      "0s - loss: 0.8958 - val_loss: 0.9148\n",
      "Epoch 28/1000\n",
      "0s - loss: 0.8859 - val_loss: 0.9039\n",
      "Epoch 29/1000\n",
      "0s - loss: 0.8769 - val_loss: 0.8932\n",
      "Epoch 30/1000\n",
      "0s - loss: 0.8689 - val_loss: 0.8825\n",
      "Epoch 31/1000\n",
      "0s - loss: 0.8584 - val_loss: 0.8721\n",
      "Epoch 32/1000\n",
      "0s - loss: 0.8491 - val_loss: 0.8618\n",
      "Epoch 33/1000\n",
      "0s - loss: 0.8402 - val_loss: 0.8515\n",
      "Epoch 34/1000\n",
      "0s - loss: 0.8319 - val_loss: 0.8415\n",
      "Epoch 35/1000\n",
      "0s - loss: 0.8230 - val_loss: 0.8313\n",
      "Epoch 36/1000\n",
      "0s - loss: 0.8142 - val_loss: 0.8218\n",
      "Epoch 37/1000\n",
      "0s - loss: 0.8062 - val_loss: 0.8114\n",
      "Epoch 38/1000\n",
      "0s - loss: 0.7972 - val_loss: 0.8018\n",
      "Epoch 39/1000\n",
      "0s - loss: 0.7884 - val_loss: 0.7923\n",
      "Epoch 40/1000\n",
      "0s - loss: 0.7803 - val_loss: 0.7834\n",
      "Epoch 41/1000\n",
      "0s - loss: 0.7719 - val_loss: 0.7738\n",
      "Epoch 42/1000\n",
      "0s - loss: 0.7630 - val_loss: 0.7650\n",
      "Epoch 43/1000\n",
      "0s - loss: 0.7551 - val_loss: 0.7560\n",
      "Epoch 44/1000\n",
      "0s - loss: 0.7467 - val_loss: 0.7463\n",
      "Epoch 45/1000\n",
      "0s - loss: 0.7384 - val_loss: 0.7368\n",
      "Epoch 46/1000\n",
      "0s - loss: 0.7300 - val_loss: 0.7278\n",
      "Epoch 47/1000\n",
      "0s - loss: 0.7220 - val_loss: 0.7187\n",
      "Epoch 48/1000\n",
      "0s - loss: 0.7138 - val_loss: 0.7097\n",
      "Epoch 49/1000\n",
      "0s - loss: 0.7055 - val_loss: 0.7009\n",
      "Epoch 50/1000\n",
      "0s - loss: 0.6976 - val_loss: 0.6916\n",
      "Epoch 51/1000\n",
      "0s - loss: 0.6897 - val_loss: 0.6826\n",
      "Epoch 52/1000\n",
      "0s - loss: 0.6824 - val_loss: 0.6742\n",
      "Epoch 53/1000\n",
      "0s - loss: 0.6743 - val_loss: 0.6652\n",
      "Epoch 54/1000\n",
      "0s - loss: 0.6662 - val_loss: 0.6566\n",
      "Epoch 55/1000\n",
      "0s - loss: 0.6586 - val_loss: 0.6482\n",
      "Epoch 56/1000\n",
      "0s - loss: 0.6511 - val_loss: 0.6400\n",
      "Epoch 57/1000\n",
      "0s - loss: 0.6452 - val_loss: 0.6312\n",
      "Epoch 58/1000\n",
      "0s - loss: 0.6357 - val_loss: 0.6231\n",
      "Epoch 59/1000\n",
      "0s - loss: 0.6289 - val_loss: 0.6155\n",
      "Epoch 60/1000\n",
      "0s - loss: 0.6211 - val_loss: 0.6075\n",
      "Epoch 61/1000\n",
      "0s - loss: 0.6139 - val_loss: 0.5989\n",
      "Epoch 62/1000\n",
      "0s - loss: 0.6060 - val_loss: 0.5911\n",
      "Epoch 63/1000\n",
      "0s - loss: 0.5986 - val_loss: 0.5831\n",
      "Epoch 64/1000\n",
      "0s - loss: 0.5916 - val_loss: 0.5753\n",
      "Epoch 65/1000\n",
      "0s - loss: 0.5846 - val_loss: 0.5667\n",
      "Epoch 66/1000\n",
      "0s - loss: 0.5769 - val_loss: 0.5588\n",
      "Epoch 67/1000\n",
      "0s - loss: 0.5704 - val_loss: 0.5512\n",
      "Epoch 68/1000\n",
      "0s - loss: 0.5632 - val_loss: 0.5432\n",
      "Epoch 69/1000\n",
      "0s - loss: 0.5558 - val_loss: 0.5368\n",
      "Epoch 70/1000\n",
      "0s - loss: 0.5490 - val_loss: 0.5285\n",
      "Epoch 71/1000\n",
      "0s - loss: 0.5435 - val_loss: 0.5210\n",
      "Epoch 72/1000\n",
      "0s - loss: 0.5347 - val_loss: 0.5127\n",
      "Epoch 73/1000\n",
      "0s - loss: 0.5278 - val_loss: 0.5049\n",
      "Epoch 74/1000\n",
      "0s - loss: 0.5217 - val_loss: 0.4974\n",
      "Epoch 75/1000\n",
      "0s - loss: 0.5143 - val_loss: 0.4902\n",
      "Epoch 76/1000\n",
      "0s - loss: 0.5079 - val_loss: 0.4841\n",
      "Epoch 77/1000\n",
      "0s - loss: 0.5014 - val_loss: 0.4768\n",
      "Epoch 78/1000\n",
      "0s - loss: 0.4948 - val_loss: 0.4701\n",
      "Epoch 79/1000\n",
      "0s - loss: 0.4906 - val_loss: 0.4623\n",
      "Epoch 80/1000\n",
      "0s - loss: 0.4827 - val_loss: 0.4560\n",
      "Epoch 81/1000\n",
      "0s - loss: 0.4760 - val_loss: 0.4492\n",
      "Epoch 82/1000\n",
      "0s - loss: 0.4697 - val_loss: 0.4424\n",
      "Epoch 83/1000\n",
      "0s - loss: 0.4642 - val_loss: 0.4360\n",
      "Epoch 84/1000\n",
      "0s - loss: 0.4581 - val_loss: 0.4295\n",
      "Epoch 85/1000\n",
      "0s - loss: 0.4521 - val_loss: 0.4233\n",
      "Epoch 86/1000\n",
      "0s - loss: 0.4460 - val_loss: 0.4174\n",
      "Epoch 87/1000\n",
      "0s - loss: 0.4405 - val_loss: 0.4118\n",
      "Epoch 88/1000\n",
      "0s - loss: 0.4349 - val_loss: 0.4064\n",
      "Epoch 89/1000\n",
      "0s - loss: 0.4308 - val_loss: 0.4015\n",
      "Epoch 90/1000\n",
      "0s - loss: 0.4250 - val_loss: 0.3948\n",
      "Epoch 91/1000\n",
      "0s - loss: 0.4188 - val_loss: 0.3891\n",
      "Epoch 92/1000\n",
      "0s - loss: 0.4143 - val_loss: 0.3839\n",
      "Epoch 93/1000\n",
      "0s - loss: 0.4087 - val_loss: 0.3782\n",
      "Epoch 94/1000\n",
      "0s - loss: 0.4041 - val_loss: 0.3730\n",
      "Epoch 95/1000\n",
      "0s - loss: 0.3997 - val_loss: 0.3680\n",
      "Epoch 96/1000\n",
      "0s - loss: 0.3939 - val_loss: 0.3627\n",
      "Epoch 97/1000\n",
      "0s - loss: 0.3901 - val_loss: 0.3581\n",
      "Epoch 98/1000\n",
      "0s - loss: 0.3856 - val_loss: 0.3531\n",
      "Epoch 99/1000\n",
      "0s - loss: 0.3800 - val_loss: 0.3484\n",
      "Epoch 100/1000\n",
      "0s - loss: 0.3753 - val_loss: 0.3439\n",
      "Epoch 101/1000\n",
      "0s - loss: 0.3711 - val_loss: 0.3395\n",
      "Epoch 102/1000\n",
      "0s - loss: 0.3665 - val_loss: 0.3351\n",
      "Epoch 103/1000\n",
      "0s - loss: 0.3623 - val_loss: 0.3312\n",
      "Epoch 104/1000\n",
      "0s - loss: 0.3581 - val_loss: 0.3270\n",
      "Epoch 105/1000\n",
      "0s - loss: 0.3542 - val_loss: 0.3226\n",
      "Epoch 106/1000\n",
      "0s - loss: 0.3510 - val_loss: 0.3184\n",
      "Epoch 107/1000\n",
      "0s - loss: 0.3460 - val_loss: 0.3142\n",
      "Epoch 108/1000\n",
      "0s - loss: 0.3417 - val_loss: 0.3101\n",
      "Epoch 109/1000\n",
      "0s - loss: 0.3380 - val_loss: 0.3062\n",
      "Epoch 110/1000\n",
      "0s - loss: 0.3341 - val_loss: 0.3028\n",
      "Epoch 111/1000\n",
      "0s - loss: 0.3306 - val_loss: 0.2992\n",
      "Epoch 112/1000\n",
      "0s - loss: 0.3267 - val_loss: 0.2955\n",
      "Epoch 113/1000\n",
      "0s - loss: 0.3230 - val_loss: 0.2913\n",
      "Epoch 114/1000\n",
      "0s - loss: 0.3199 - val_loss: 0.2879\n",
      "Epoch 115/1000\n",
      "0s - loss: 0.3156 - val_loss: 0.2842\n",
      "Epoch 116/1000\n",
      "0s - loss: 0.3119 - val_loss: 0.2806\n",
      "Epoch 117/1000\n",
      "0s - loss: 0.3092 - val_loss: 0.2773\n",
      "Epoch 118/1000\n",
      "0s - loss: 0.3050 - val_loss: 0.2738\n",
      "Epoch 119/1000\n",
      "0s - loss: 0.3019 - val_loss: 0.2704\n",
      "Epoch 120/1000\n",
      "0s - loss: 0.2987 - val_loss: 0.2670\n",
      "Epoch 121/1000\n",
      "0s - loss: 0.2952 - val_loss: 0.2638\n",
      "Epoch 122/1000\n",
      "0s - loss: 0.2924 - val_loss: 0.2607\n",
      "Epoch 123/1000\n",
      "0s - loss: 0.2890 - val_loss: 0.2577\n",
      "Epoch 124/1000\n",
      "0s - loss: 0.2860 - val_loss: 0.2545\n",
      "Epoch 125/1000\n",
      "0s - loss: 0.2830 - val_loss: 0.2519\n",
      "Epoch 126/1000\n",
      "0s - loss: 0.2797 - val_loss: 0.2490\n",
      "Epoch 127/1000\n",
      "0s - loss: 0.2761 - val_loss: 0.2456\n",
      "Epoch 128/1000\n",
      "0s - loss: 0.2735 - val_loss: 0.2427\n",
      "Epoch 129/1000\n",
      "0s - loss: 0.2707 - val_loss: 0.2397\n",
      "Epoch 130/1000\n",
      "0s - loss: 0.2681 - val_loss: 0.2370\n",
      "Epoch 131/1000\n",
      "0s - loss: 0.2652 - val_loss: 0.2342\n",
      "Epoch 132/1000\n",
      "0s - loss: 0.2622 - val_loss: 0.2314\n",
      "Epoch 133/1000\n",
      "0s - loss: 0.2592 - val_loss: 0.2289\n",
      "Epoch 134/1000\n",
      "0s - loss: 0.2567 - val_loss: 0.2262\n",
      "Epoch 135/1000\n",
      "0s - loss: 0.2537 - val_loss: 0.2237\n",
      "Epoch 136/1000\n",
      "0s - loss: 0.2508 - val_loss: 0.2209\n",
      "Epoch 137/1000\n",
      "0s - loss: 0.2486 - val_loss: 0.2183\n",
      "Epoch 138/1000\n",
      "0s - loss: 0.2460 - val_loss: 0.2159\n",
      "Epoch 139/1000\n",
      "0s - loss: 0.2433 - val_loss: 0.2135\n",
      "Epoch 140/1000\n",
      "0s - loss: 0.2416 - val_loss: 0.2109\n",
      "Epoch 141/1000\n",
      "0s - loss: 0.2387 - val_loss: 0.2094\n",
      "Epoch 142/1000\n",
      "0s - loss: 0.2370 - val_loss: 0.2074\n",
      "Epoch 143/1000\n",
      "0s - loss: 0.2350 - val_loss: 0.2038\n",
      "Epoch 144/1000\n",
      "0s - loss: 0.2314 - val_loss: 0.2015\n",
      "Epoch 145/1000\n",
      "0s - loss: 0.2287 - val_loss: 0.1995\n",
      "Epoch 146/1000\n",
      "0s - loss: 0.2269 - val_loss: 0.1977\n",
      "Epoch 147/1000\n",
      "0s - loss: 0.2238 - val_loss: 0.1950\n",
      "Epoch 148/1000\n",
      "0s - loss: 0.2216 - val_loss: 0.1927\n",
      "Epoch 149/1000\n",
      "0s - loss: 0.2195 - val_loss: 0.1906\n",
      "Epoch 150/1000\n",
      "0s - loss: 0.2178 - val_loss: 0.1887\n",
      "Epoch 151/1000\n",
      "0s - loss: 0.2152 - val_loss: 0.1868\n",
      "Epoch 152/1000\n",
      "0s - loss: 0.2138 - val_loss: 0.1856\n",
      "Epoch 153/1000\n",
      "0s - loss: 0.2112 - val_loss: 0.1834\n",
      "Epoch 154/1000\n",
      "0s - loss: 0.2087 - val_loss: 0.1812\n",
      "Epoch 155/1000\n",
      "0s - loss: 0.2082 - val_loss: 0.1790\n",
      "Epoch 156/1000\n",
      "0s - loss: 0.2046 - val_loss: 0.1770\n",
      "Epoch 157/1000\n",
      "0s - loss: 0.2027 - val_loss: 0.1759\n",
      "Epoch 158/1000\n",
      "0s - loss: 0.2005 - val_loss: 0.1738\n",
      "Epoch 159/1000\n",
      "0s - loss: 0.1993 - val_loss: 0.1713\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.1975 - val_loss: 0.1694\n",
      "Epoch 161/1000\n",
      "0s - loss: 0.1946 - val_loss: 0.1680\n",
      "Epoch 162/1000\n",
      "0s - loss: 0.1931 - val_loss: 0.1677\n",
      "Epoch 163/1000\n",
      "0s - loss: 0.1916 - val_loss: 0.1650\n",
      "Epoch 164/1000\n",
      "0s - loss: 0.1895 - val_loss: 0.1625\n",
      "Epoch 165/1000\n",
      "0s - loss: 0.1876 - val_loss: 0.1610\n",
      "Epoch 166/1000\n",
      "0s - loss: 0.1855 - val_loss: 0.1591\n",
      "Epoch 167/1000\n",
      "0s - loss: 0.1839 - val_loss: 0.1573\n",
      "Epoch 168/1000\n",
      "0s - loss: 0.1821 - val_loss: 0.1557\n",
      "Epoch 169/1000\n",
      "0s - loss: 0.1805 - val_loss: 0.1542\n",
      "Epoch 170/1000\n",
      "0s - loss: 0.1790 - val_loss: 0.1530\n",
      "Epoch 171/1000\n",
      "0s - loss: 0.1773 - val_loss: 0.1514\n",
      "Epoch 172/1000\n",
      "0s - loss: 0.1769 - val_loss: 0.1494\n",
      "Epoch 173/1000\n",
      "0s - loss: 0.1748 - val_loss: 0.1478\n",
      "Epoch 174/1000\n",
      "0s - loss: 0.1725 - val_loss: 0.1464\n",
      "Epoch 175/1000\n",
      "0s - loss: 0.1709 - val_loss: 0.1451\n",
      "Epoch 176/1000\n",
      "0s - loss: 0.1695 - val_loss: 0.1440\n",
      "Epoch 177/1000\n",
      "0s - loss: 0.1682 - val_loss: 0.1434\n",
      "Epoch 178/1000\n",
      "0s - loss: 0.1679 - val_loss: 0.1407\n",
      "Epoch 179/1000\n",
      "0s - loss: 0.1651 - val_loss: 0.1394\n",
      "Epoch 180/1000\n",
      "0s - loss: 0.1640 - val_loss: 0.1383\n",
      "Epoch 181/1000\n",
      "0s - loss: 0.1621 - val_loss: 0.1371\n",
      "Epoch 182/1000\n",
      "0s - loss: 0.1609 - val_loss: 0.1359\n",
      "Epoch 183/1000\n",
      "0s - loss: 0.1596 - val_loss: 0.1343\n",
      "Epoch 184/1000\n",
      "0s - loss: 0.1584 - val_loss: 0.1335\n",
      "Epoch 185/1000\n",
      "0s - loss: 0.1576 - val_loss: 0.1323\n",
      "Epoch 186/1000\n",
      "0s - loss: 0.1560 - val_loss: 0.1304\n",
      "Epoch 187/1000\n",
      "0s - loss: 0.1544 - val_loss: 0.1291\n",
      "Epoch 188/1000\n",
      "0s - loss: 0.1542 - val_loss: 0.1279\n",
      "Epoch 189/1000\n",
      "0s - loss: 0.1528 - val_loss: 0.1282\n",
      "Epoch 190/1000\n",
      "0s - loss: 0.1511 - val_loss: 0.1267\n",
      "Epoch 191/1000\n",
      "0s - loss: 0.1505 - val_loss: 0.1251\n",
      "Epoch 192/1000\n",
      "0s - loss: 0.1487 - val_loss: 0.1243\n",
      "Epoch 193/1000\n",
      "0s - loss: 0.1481 - val_loss: 0.1225\n",
      "Epoch 194/1000\n",
      "0s - loss: 0.1469 - val_loss: 0.1222\n",
      "Epoch 195/1000\n",
      "0s - loss: 0.1460 - val_loss: 0.1213\n",
      "Epoch 196/1000\n",
      "0s - loss: 0.1452 - val_loss: 0.1192\n",
      "Epoch 197/1000\n",
      "0s - loss: 0.1444 - val_loss: 0.1182\n",
      "Epoch 198/1000\n",
      "0s - loss: 0.1425 - val_loss: 0.1183\n",
      "Epoch 199/1000\n",
      "0s - loss: 0.1421 - val_loss: 0.1183\n",
      "Epoch 200/1000\n",
      "0s - loss: 0.1407 - val_loss: 0.1166\n",
      "Epoch 201/1000\n",
      "0s - loss: 0.1389 - val_loss: 0.1148\n",
      "Epoch 202/1000\n",
      "0s - loss: 0.1381 - val_loss: 0.1135\n",
      "Epoch 203/1000\n",
      "0s - loss: 0.1375 - val_loss: 0.1127\n",
      "Epoch 204/1000\n",
      "0s - loss: 0.1371 - val_loss: 0.1125\n",
      "Epoch 205/1000\n",
      "0s - loss: 0.1355 - val_loss: 0.1109\n",
      "Epoch 206/1000\n",
      "0s - loss: 0.1342 - val_loss: 0.1103\n",
      "Epoch 207/1000\n",
      "0s - loss: 0.1335 - val_loss: 0.1100\n",
      "Epoch 208/1000\n",
      "0s - loss: 0.1326 - val_loss: 0.1089\n",
      "Epoch 209/1000\n",
      "0s - loss: 0.1318 - val_loss: 0.1078\n",
      "Epoch 210/1000\n",
      "0s - loss: 0.1307 - val_loss: 0.1070\n",
      "Epoch 211/1000\n",
      "0s - loss: 0.1298 - val_loss: 0.1064\n",
      "Epoch 212/1000\n",
      "0s - loss: 0.1296 - val_loss: 0.1067\n",
      "Epoch 213/1000\n",
      "0s - loss: 0.1284 - val_loss: 0.1046\n",
      "Epoch 214/1000\n",
      "0s - loss: 0.1290 - val_loss: 0.1033\n",
      "Epoch 215/1000\n",
      "0s - loss: 0.1268 - val_loss: 0.1031\n",
      "Epoch 216/1000\n",
      "0s - loss: 0.1259 - val_loss: 0.1034\n",
      "Epoch 217/1000\n",
      "0s - loss: 0.1252 - val_loss: 0.1019\n",
      "Epoch 218/1000\n",
      "0s - loss: 0.1249 - val_loss: 0.1003\n",
      "Epoch 219/1000\n",
      "0s - loss: 0.1236 - val_loss: 0.1000\n",
      "Epoch 220/1000\n",
      "0s - loss: 0.1230 - val_loss: 0.0995\n",
      "Epoch 221/1000\n",
      "0s - loss: 0.1220 - val_loss: 0.0990\n",
      "Epoch 222/1000\n",
      "0s - loss: 0.1213 - val_loss: 0.0976\n",
      "Epoch 223/1000\n",
      "0s - loss: 0.1204 - val_loss: 0.0968\n",
      "Epoch 224/1000\n",
      "0s - loss: 0.1207 - val_loss: 0.0960\n",
      "Epoch 225/1000\n",
      "0s - loss: 0.1187 - val_loss: 0.0963\n",
      "Epoch 226/1000\n",
      "0s - loss: 0.1196 - val_loss: 0.0975\n",
      "Epoch 227/1000\n",
      "0s - loss: 0.1192 - val_loss: 0.0969\n",
      "Epoch 228/1000\n",
      "0s - loss: 0.1182 - val_loss: 0.0936\n",
      "Epoch 229/1000\n",
      "0s - loss: 0.1166 - val_loss: 0.0927\n",
      "Epoch 230/1000\n",
      "0s - loss: 0.1156 - val_loss: 0.0925\n",
      "Epoch 231/1000\n",
      "0s - loss: 0.1160 - val_loss: 0.0934\n",
      "Epoch 232/1000\n",
      "0s - loss: 0.1150 - val_loss: 0.0921\n",
      "Epoch 233/1000\n",
      "0s - loss: 0.1135 - val_loss: 0.0902\n",
      "Epoch 234/1000\n",
      "0s - loss: 0.1141 - val_loss: 0.0895\n",
      "Epoch 235/1000\n",
      "0s - loss: 0.1135 - val_loss: 0.0891\n",
      "Epoch 236/1000\n",
      "0s - loss: 0.1116 - val_loss: 0.0901\n",
      "Epoch 237/1000\n",
      "0s - loss: 0.1118 - val_loss: 0.0903\n",
      "Epoch 238/1000\n",
      "0s - loss: 0.1112 - val_loss: 0.0879\n",
      "Epoch 239/1000\n",
      "0s - loss: 0.1105 - val_loss: 0.0868\n",
      "Epoch 240/1000\n",
      "0s - loss: 0.1119 - val_loss: 0.0879\n",
      "Epoch 241/1000\n",
      "0s - loss: 0.1092 - val_loss: 0.0859\n",
      "Epoch 242/1000\n",
      "0s - loss: 0.1087 - val_loss: 0.0852\n",
      "Epoch 243/1000\n",
      "0s - loss: 0.1082 - val_loss: 0.0850\n",
      "Epoch 244/1000\n",
      "0s - loss: 0.1073 - val_loss: 0.0856\n",
      "Epoch 245/1000\n",
      "0s - loss: 0.1077 - val_loss: 0.0864\n",
      "Epoch 246/1000\n",
      "0s - loss: 0.1065 - val_loss: 0.0833\n",
      "Epoch 247/1000\n",
      "0s - loss: 0.1063 - val_loss: 0.0824\n",
      "Epoch 248/1000\n",
      "0s - loss: 0.1063 - val_loss: 0.0827\n",
      "Epoch 249/1000\n",
      "0s - loss: 0.1050 - val_loss: 0.0824\n",
      "Epoch 250/1000\n",
      "0s - loss: 0.1042 - val_loss: 0.0817\n",
      "Epoch 251/1000\n",
      "0s - loss: 0.1037 - val_loss: 0.0814\n",
      "Epoch 252/1000\n",
      "0s - loss: 0.1041 - val_loss: 0.0802\n",
      "Epoch 253/1000\n",
      "0s - loss: 0.1028 - val_loss: 0.0812\n",
      "Epoch 254/1000\n",
      "0s - loss: 0.1022 - val_loss: 0.0809\n",
      "Epoch 255/1000\n",
      "0s - loss: 0.1018 - val_loss: 0.0795\n",
      "Epoch 256/1000\n",
      "0s - loss: 0.1012 - val_loss: 0.0790\n",
      "Epoch 257/1000\n",
      "0s - loss: 0.1012 - val_loss: 0.0782\n",
      "Epoch 258/1000\n",
      "0s - loss: 0.1011 - val_loss: 0.0787\n",
      "Epoch 259/1000\n",
      "0s - loss: 0.0999 - val_loss: 0.0774\n",
      "Epoch 260/1000\n",
      "0s - loss: 0.0995 - val_loss: 0.0771\n",
      "Epoch 261/1000\n",
      "0s - loss: 0.0997 - val_loss: 0.0762\n",
      "Epoch 262/1000\n",
      "0s - loss: 0.0988 - val_loss: 0.0773\n",
      "Epoch 263/1000\n",
      "0s - loss: 0.0987 - val_loss: 0.0772\n",
      "Epoch 264/1000\n",
      "0s - loss: 0.0984 - val_loss: 0.0780\n",
      "Epoch 265/1000\n",
      "0s - loss: 0.0983 - val_loss: 0.0752\n",
      "Epoch 266/1000\n",
      "0s - loss: 0.0970 - val_loss: 0.0748\n",
      "Epoch 267/1000\n",
      "0s - loss: 0.0965 - val_loss: 0.0739\n",
      "Epoch 268/1000\n",
      "0s - loss: 0.0962 - val_loss: 0.0734\n",
      "Epoch 269/1000\n",
      "0s - loss: 0.0974 - val_loss: 0.0728\n",
      "Epoch 270/1000\n",
      "0s - loss: 0.0951 - val_loss: 0.0742\n",
      "Epoch 271/1000\n",
      "0s - loss: 0.0950 - val_loss: 0.0746\n",
      "Epoch 272/1000\n",
      "0s - loss: 0.0949 - val_loss: 0.0737\n",
      "Epoch 273/1000\n",
      "0s - loss: 0.0940 - val_loss: 0.0715\n",
      "Epoch 274/1000\n",
      "0s - loss: 0.0946 - val_loss: 0.0713\n",
      "Epoch 275/1000\n",
      "0s - loss: 0.0938 - val_loss: 0.0712\n",
      "Epoch 276/1000\n",
      "0s - loss: 0.0932 - val_loss: 0.0703\n",
      "Epoch 277/1000\n",
      "0s - loss: 0.0929 - val_loss: 0.0701\n",
      "Epoch 278/1000\n",
      "0s - loss: 0.0927 - val_loss: 0.0706\n",
      "Epoch 279/1000\n",
      "0s - loss: 0.0919 - val_loss: 0.0702\n",
      "Epoch 280/1000\n",
      "0s - loss: 0.0924 - val_loss: 0.0697\n",
      "Epoch 281/1000\n",
      "0s - loss: 0.0914 - val_loss: 0.0694\n",
      "Epoch 282/1000\n",
      "0s - loss: 0.0912 - val_loss: 0.0702\n",
      "Epoch 283/1000\n",
      "0s - loss: 0.0908 - val_loss: 0.0696\n",
      "Epoch 284/1000\n",
      "0s - loss: 0.0912 - val_loss: 0.0689\n",
      "Epoch 285/1000\n",
      "0s - loss: 0.0900 - val_loss: 0.0670\n",
      "Epoch 286/1000\n",
      "0s - loss: 0.0904 - val_loss: 0.0666\n",
      "Epoch 287/1000\n",
      "0s - loss: 0.0895 - val_loss: 0.0672\n",
      "Epoch 288/1000\n",
      "0s - loss: 0.0887 - val_loss: 0.0683\n",
      "Epoch 289/1000\n",
      "0s - loss: 0.0894 - val_loss: 0.0692\n",
      "Epoch 290/1000\n",
      "0s - loss: 0.0886 - val_loss: 0.0673\n",
      "Epoch 291/1000\n",
      "0s - loss: 0.0892 - val_loss: 0.0651\n",
      "Epoch 292/1000\n",
      "0s - loss: 0.0896 - val_loss: 0.0648\n",
      "Epoch 293/1000\n",
      "0s - loss: 0.0876 - val_loss: 0.0657\n",
      "Epoch 294/1000\n",
      "0s - loss: 0.0877 - val_loss: 0.0657\n",
      "Epoch 295/1000\n",
      "0s - loss: 0.0870 - val_loss: 0.0659\n",
      "Epoch 296/1000\n",
      "0s - loss: 0.0865 - val_loss: 0.0647\n",
      "Epoch 297/1000\n",
      "0s - loss: 0.0881 - val_loss: 0.0634\n",
      "Epoch 298/1000\n",
      "0s - loss: 0.0876 - val_loss: 0.0653\n",
      "Epoch 299/1000\n",
      "0s - loss: 0.0866 - val_loss: 0.0634\n",
      "Epoch 300/1000\n",
      "0s - loss: 0.0861 - val_loss: 0.0645\n",
      "Epoch 301/1000\n",
      "0s - loss: 0.0856 - val_loss: 0.0634\n",
      "Epoch 302/1000\n",
      "0s - loss: 0.0853 - val_loss: 0.0631\n",
      "Epoch 303/1000\n",
      "0s - loss: 0.0856 - val_loss: 0.0617\n",
      "Epoch 304/1000\n",
      "0s - loss: 0.0849 - val_loss: 0.0625\n",
      "Epoch 305/1000\n",
      "0s - loss: 0.0847 - val_loss: 0.0631\n",
      "Epoch 306/1000\n",
      "0s - loss: 0.0854 - val_loss: 0.0610\n",
      "Epoch 307/1000\n",
      "0s - loss: 0.0841 - val_loss: 0.0622\n",
      "Epoch 308/1000\n",
      "0s - loss: 0.0838 - val_loss: 0.0628\n",
      "Epoch 309/1000\n",
      "0s - loss: 0.0834 - val_loss: 0.0608\n",
      "Epoch 310/1000\n",
      "0s - loss: 0.0832 - val_loss: 0.0602\n",
      "Epoch 311/1000\n",
      "0s - loss: 0.0825 - val_loss: 0.0607\n",
      "Epoch 312/1000\n",
      "0s - loss: 0.0822 - val_loss: 0.0611\n",
      "Epoch 313/1000\n",
      "0s - loss: 0.0826 - val_loss: 0.0614\n",
      "Epoch 314/1000\n",
      "0s - loss: 0.0820 - val_loss: 0.0611\n",
      "Epoch 315/1000\n",
      "0s - loss: 0.0817 - val_loss: 0.0596\n",
      "Epoch 316/1000\n",
      "0s - loss: 0.0814 - val_loss: 0.0586\n",
      "Epoch 317/1000\n",
      "0s - loss: 0.0816 - val_loss: 0.0590\n",
      "Epoch 318/1000\n",
      "0s - loss: 0.0808 - val_loss: 0.0590\n",
      "Epoch 319/1000\n",
      "0s - loss: 0.0810 - val_loss: 0.0592\n",
      "Epoch 320/1000\n",
      "0s - loss: 0.0805 - val_loss: 0.0586\n",
      "Epoch 321/1000\n",
      "0s - loss: 0.0802 - val_loss: 0.0585\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0800 - val_loss: 0.0577\n",
      "Epoch 323/1000\n",
      "0s - loss: 0.0803 - val_loss: 0.0583\n",
      "Epoch 324/1000\n",
      "0s - loss: 0.0798 - val_loss: 0.0569\n",
      "Epoch 325/1000\n",
      "0s - loss: 0.0793 - val_loss: 0.0571\n",
      "Epoch 326/1000\n",
      "0s - loss: 0.0790 - val_loss: 0.0577\n",
      "Epoch 327/1000\n",
      "0s - loss: 0.0790 - val_loss: 0.0581\n",
      "Epoch 328/1000\n",
      "0s - loss: 0.0789 - val_loss: 0.0577\n",
      "Epoch 329/1000\n",
      "0s - loss: 0.0783 - val_loss: 0.0558\n",
      "Epoch 330/1000\n",
      "0s - loss: 0.0785 - val_loss: 0.0554\n",
      "Epoch 331/1000\n",
      "0s - loss: 0.0787 - val_loss: 0.0553\n",
      "Epoch 332/1000\n",
      "0s - loss: 0.0786 - val_loss: 0.0572\n",
      "Epoch 333/1000\n",
      "0s - loss: 0.0782 - val_loss: 0.0570\n",
      "Epoch 334/1000\n",
      "0s - loss: 0.0784 - val_loss: 0.0547\n",
      "Epoch 335/1000\n",
      "0s - loss: 0.0773 - val_loss: 0.0551\n",
      "Epoch 336/1000\n",
      "0s - loss: 0.0773 - val_loss: 0.0555\n",
      "Epoch 337/1000\n",
      "0s - loss: 0.0778 - val_loss: 0.0565\n",
      "Epoch 338/1000\n",
      "0s - loss: 0.0770 - val_loss: 0.0554\n",
      "Epoch 339/1000\n",
      "0s - loss: 0.0772 - val_loss: 0.0550\n",
      "Epoch 340/1000\n",
      "0s - loss: 0.0768 - val_loss: 0.0535\n",
      "Epoch 341/1000\n",
      "0s - loss: 0.0766 - val_loss: 0.0537\n",
      "Epoch 342/1000\n",
      "0s - loss: 0.0759 - val_loss: 0.0537\n",
      "Epoch 343/1000\n",
      "0s - loss: 0.0760 - val_loss: 0.0538\n",
      "Epoch 344/1000\n",
      "0s - loss: 0.0759 - val_loss: 0.0532\n",
      "Epoch 345/1000\n",
      "0s - loss: 0.0753 - val_loss: 0.0526\n",
      "Epoch 346/1000\n",
      "0s - loss: 0.0758 - val_loss: 0.0521\n",
      "Epoch 347/1000\n",
      "0s - loss: 0.0789 - val_loss: 0.0558\n",
      "Epoch 348/1000\n",
      "0s - loss: 0.0757 - val_loss: 0.0533\n",
      "Epoch 349/1000\n",
      "0s - loss: 0.0749 - val_loss: 0.0527\n",
      "Epoch 350/1000\n",
      "0s - loss: 0.0751 - val_loss: 0.0511\n",
      "Epoch 351/1000\n",
      "0s - loss: 0.0756 - val_loss: 0.0511\n",
      "Epoch 352/1000\n",
      "0s - loss: 0.0760 - val_loss: 0.0546\n",
      "Epoch 353/1000\n",
      "0s - loss: 0.0746 - val_loss: 0.0529\n",
      "Epoch 354/1000\n",
      "0s - loss: 0.0739 - val_loss: 0.0516\n",
      "Epoch 355/1000\n",
      "0s - loss: 0.0739 - val_loss: 0.0516\n",
      "Epoch 356/1000\n",
      "0s - loss: 0.0746 - val_loss: 0.0508\n",
      "Epoch 357/1000\n",
      "0s - loss: 0.0733 - val_loss: 0.0518\n",
      "Epoch 358/1000\n",
      "0s - loss: 0.0743 - val_loss: 0.0509\n",
      "Epoch 359/1000\n",
      "0s - loss: 0.0734 - val_loss: 0.0527\n",
      "Epoch 00358: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "species = encode_text_index(df,\"species\")\n",
    "x,y = to_xy(df,\"species\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=7, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath='best_weights.hdf5', verbose=0, save_best_only=True)\n",
    "model.fit(x,y,validation_data=(x_test,y_test), callbacks=[monitor,checkpointer], verbose=2, epochs=1000 )\n",
    "model.load_weights('best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 2 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(pred,axis=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Accuracy Score is 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "y_compare=np.argmax(y_test,axis=1)\n",
    "score=metrics.accuracy_score(y_compare,pred)\n",
    "print('the Accuracy Score is {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array of predictions\n",
      "[  0.0494  95.591    4.3595]\n",
      "As percent probability\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0005,  0.9559,  0.0436],\n",
       "       [ 0.9974,  0.0026,  0.    ],\n",
       "       [ 0.    ,  0.0003,  0.9997],\n",
       "       [ 0.0005,  0.8938,  0.1057],\n",
       "       [ 0.0004,  0.9693,  0.0303]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Log Loss score 0.050843220379503784\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pred=model.predict(x_test)\n",
    "print(\"Numpy array of predictions\")\n",
    "print(pred[0]*100)\n",
    "\n",
    "print(\"As percent probability\")\n",
    "display(pred[0:5])\n",
    "\n",
    "score=metrics.log_loss(y_test,pred)\n",
    "print('The Log Loss score {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAE0CAYAAAASSJRcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x169648a2668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import sin, pi, arange\n",
    "\n",
    "\n",
    "t=arange(0.0,1.0,0.00001)\n",
    "fig=figure(1,figsize=(12,10))\n",
    "ax1=fig.add_subplot(211)\n",
    "ax1.plot(t,np.log(t))\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim((-8, 1.5))\n",
    "ax1.set_xlim((-0.1, 2))\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('log(x)')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "0s - loss: 40549.2783 - val_loss: 298.9359\n",
      "Epoch 2/1000\n",
      "0s - loss: 5034.8022 - val_loss: 4245.0559\n",
      "Epoch 3/1000\n",
      "0s - loss: 1251.0944 - val_loss: 772.3616\n",
      "Epoch 4/1000\n",
      "0s - loss: 704.5763 - val_loss: 141.4058\n",
      "Epoch 5/1000\n",
      "0s - loss: 170.0515 - val_loss: 176.6356\n",
      "Epoch 6/1000\n",
      "0s - loss: 133.6015 - val_loss: 110.8262\n",
      "Epoch 7/1000\n",
      "0s - loss: 122.5023 - val_loss: 87.7430\n",
      "Epoch 8/1000\n",
      "0s - loss: 112.9379 - val_loss: 87.8483\n",
      "Epoch 9/1000\n",
      "0s - loss: 109.3203 - val_loss: 88.5815\n",
      "Epoch 10/1000\n",
      "0s - loss: 109.9569 - val_loss: 86.4964\n",
      "Epoch 11/1000\n",
      "0s - loss: 108.6625 - val_loss: 86.2154\n",
      "Epoch 12/1000\n",
      "0s - loss: 108.1217 - val_loss: 86.4120\n",
      "Epoch 13/1000\n",
      "0s - loss: 107.7531 - val_loss: 85.0086\n",
      "Epoch 14/1000\n",
      "0s - loss: 106.8036 - val_loss: 85.2011\n",
      "Epoch 15/1000\n",
      "0s - loss: 106.4683 - val_loss: 83.8949\n",
      "Epoch 16/1000\n",
      "0s - loss: 105.5997 - val_loss: 84.5968\n",
      "Epoch 17/1000\n",
      "0s - loss: 105.9625 - val_loss: 82.8928\n",
      "Epoch 18/1000\n",
      "0s - loss: 104.1290 - val_loss: 82.8704\n",
      "Epoch 19/1000\n",
      "0s - loss: 103.8487 - val_loss: 81.5864\n",
      "Epoch 20/1000\n",
      "0s - loss: 102.6127 - val_loss: 80.9992\n",
      "Epoch 21/1000\n",
      "0s - loss: 102.0024 - val_loss: 80.5727\n",
      "Epoch 22/1000\n",
      "0s - loss: 101.7730 - val_loss: 79.6622\n",
      "Epoch 23/1000\n",
      "0s - loss: 101.7153 - val_loss: 78.9761\n",
      "Epoch 24/1000\n",
      "0s - loss: 102.6647 - val_loss: 78.8873\n",
      "Epoch 25/1000\n",
      "0s - loss: 103.0502 - val_loss: 79.1627\n",
      "Epoch 26/1000\n",
      "0s - loss: 98.1501 - val_loss: 76.9267\n",
      "Epoch 27/1000\n",
      "0s - loss: 97.4901 - val_loss: 76.3631\n",
      "Epoch 28/1000\n",
      "0s - loss: 96.0895 - val_loss: 75.4328\n",
      "Epoch 29/1000\n",
      "0s - loss: 95.4925 - val_loss: 75.3306\n",
      "Epoch 30/1000\n",
      "0s - loss: 94.8043 - val_loss: 74.6335\n",
      "Epoch 31/1000\n",
      "0s - loss: 93.3653 - val_loss: 73.1505\n",
      "Epoch 32/1000\n",
      "0s - loss: 93.2342 - val_loss: 74.6783\n",
      "Epoch 33/1000\n",
      "0s - loss: 92.4219 - val_loss: 71.6494\n",
      "Epoch 34/1000\n",
      "0s - loss: 90.2945 - val_loss: 71.9394\n",
      "Epoch 35/1000\n",
      "0s - loss: 89.6928 - val_loss: 70.3896\n",
      "Epoch 36/1000\n",
      "0s - loss: 89.5970 - val_loss: 69.6526\n",
      "Epoch 37/1000\n",
      "0s - loss: 87.9891 - val_loss: 68.8806\n",
      "Epoch 38/1000\n",
      "0s - loss: 88.0912 - val_loss: 67.8081\n",
      "Epoch 39/1000\n",
      "0s - loss: 88.9291 - val_loss: 69.0658\n",
      "Epoch 40/1000\n",
      "0s - loss: 87.4430 - val_loss: 69.1747\n",
      "Epoch 41/1000\n",
      "0s - loss: 84.3994 - val_loss: 65.5409\n",
      "Epoch 42/1000\n",
      "0s - loss: 82.8046 - val_loss: 65.0975\n",
      "Epoch 43/1000\n",
      "0s - loss: 82.0378 - val_loss: 65.8030\n",
      "Epoch 44/1000\n",
      "0s - loss: 81.7552 - val_loss: 64.0392\n",
      "Epoch 45/1000\n",
      "0s - loss: 81.4656 - val_loss: 64.5212\n",
      "Epoch 46/1000\n",
      "0s - loss: 81.3109 - val_loss: 64.2563\n",
      "Epoch 47/1000\n",
      "0s - loss: 78.2459 - val_loss: 61.1716\n",
      "Epoch 48/1000\n",
      "0s - loss: 78.3269 - val_loss: 60.7148\n",
      "Epoch 49/1000\n",
      "0s - loss: 77.0315 - val_loss: 59.7461\n",
      "Epoch 50/1000\n",
      "0s - loss: 76.2275 - val_loss: 61.1192\n",
      "Epoch 51/1000\n",
      "0s - loss: 75.4544 - val_loss: 59.0131\n",
      "Epoch 52/1000\n",
      "0s - loss: 74.9487 - val_loss: 58.6307\n",
      "Epoch 53/1000\n",
      "0s - loss: 73.4020 - val_loss: 56.9676\n",
      "Epoch 54/1000\n",
      "0s - loss: 72.3550 - val_loss: 56.3338\n",
      "Epoch 55/1000\n",
      "0s - loss: 71.8490 - val_loss: 55.7127\n",
      "Epoch 56/1000\n",
      "0s - loss: 71.0948 - val_loss: 55.4109\n",
      "Epoch 57/1000\n",
      "0s - loss: 70.5420 - val_loss: 54.6886\n",
      "Epoch 58/1000\n",
      "0s - loss: 70.6723 - val_loss: 55.7331\n",
      "Epoch 59/1000\n",
      "0s - loss: 70.2569 - val_loss: 56.8868\n",
      "Epoch 60/1000\n",
      "0s - loss: 68.6686 - val_loss: 57.4355\n",
      "Epoch 61/1000\n",
      "0s - loss: 69.2350 - val_loss: 53.3522\n",
      "Epoch 62/1000\n",
      "0s - loss: 65.5129 - val_loss: 52.8528\n",
      "Epoch 63/1000\n",
      "0s - loss: 65.6126 - val_loss: 52.8962\n",
      "Epoch 64/1000\n",
      "0s - loss: 63.8905 - val_loss: 50.4493\n",
      "Epoch 65/1000\n",
      "0s - loss: 64.5563 - val_loss: 50.4609\n",
      "Epoch 66/1000\n",
      "0s - loss: 63.9627 - val_loss: 49.6597\n",
      "Epoch 67/1000\n",
      "0s - loss: 62.9810 - val_loss: 49.2067\n",
      "Epoch 68/1000\n",
      "0s - loss: 61.3736 - val_loss: 50.5553\n",
      "Epoch 69/1000\n",
      "0s - loss: 60.7950 - val_loss: 48.4917\n",
      "Epoch 70/1000\n",
      "0s - loss: 60.5254 - val_loss: 48.7041\n",
      "Epoch 71/1000\n",
      "0s - loss: 60.0435 - val_loss: 51.5149\n",
      "Epoch 72/1000\n",
      "0s - loss: 63.9022 - val_loss: 50.1526\n",
      "Epoch 73/1000\n",
      "0s - loss: 58.9793 - val_loss: 46.7649\n",
      "Epoch 74/1000\n",
      "0s - loss: 60.3706 - val_loss: 48.3929\n",
      "Epoch 75/1000\n",
      "0s - loss: 58.7241 - val_loss: 45.5144\n",
      "Epoch 76/1000\n",
      "0s - loss: 56.3950 - val_loss: 54.1377\n",
      "Epoch 77/1000\n",
      "0s - loss: 58.8625 - val_loss: 44.9151\n",
      "Epoch 78/1000\n",
      "0s - loss: 56.5507 - val_loss: 44.4583\n",
      "Epoch 79/1000\n",
      "0s - loss: 57.3597 - val_loss: 44.7067\n",
      "Epoch 80/1000\n",
      "0s - loss: 57.7012 - val_loss: 51.1730\n",
      "Epoch 81/1000\n",
      "0s - loss: 60.3419 - val_loss: 43.4854\n",
      "Epoch 82/1000\n",
      "0s - loss: 58.0387 - val_loss: 43.2478\n",
      "Epoch 83/1000\n",
      "0s - loss: 53.7241 - val_loss: 43.1842\n",
      "Epoch 84/1000\n",
      "0s - loss: 54.1756 - val_loss: 46.5724\n",
      "Epoch 85/1000\n",
      "0s - loss: 55.3521 - val_loss: 45.3427\n",
      "Epoch 86/1000\n",
      "0s - loss: 53.6744 - val_loss: 47.1562\n",
      "Epoch 87/1000\n",
      "0s - loss: 55.5540 - val_loss: 45.7323\n",
      "Epoch 88/1000\n",
      "0s - loss: 52.7200 - val_loss: 43.0913\n",
      "Epoch 89/1000\n",
      "0s - loss: 51.1955 - val_loss: 41.1227\n",
      "Epoch 90/1000\n",
      "0s - loss: 52.3335 - val_loss: 41.9601\n",
      "Epoch 91/1000\n",
      "0s - loss: 55.2630 - val_loss: 41.9308\n",
      "Epoch 92/1000\n",
      "0s - loss: 53.1637 - val_loss: 40.1919\n",
      "Epoch 93/1000\n",
      "0s - loss: 50.2334 - val_loss: 40.0093\n",
      "Epoch 94/1000\n",
      "0s - loss: 50.9048 - val_loss: 40.2003\n",
      "Epoch 95/1000\n",
      "0s - loss: 52.6424 - val_loss: 45.9883\n",
      "Epoch 96/1000\n",
      "0s - loss: 52.2425 - val_loss: 42.2873\n",
      "Epoch 97/1000\n",
      "0s - loss: 50.7178 - val_loss: 39.7175\n",
      "Epoch 98/1000\n",
      "0s - loss: 48.2553 - val_loss: 39.3940\n",
      "Epoch 99/1000\n",
      "0s - loss: 47.7153 - val_loss: 41.8565\n",
      "Epoch 100/1000\n",
      "0s - loss: 48.8782 - val_loss: 38.1810\n",
      "Epoch 101/1000\n",
      "0s - loss: 47.5659 - val_loss: 37.9626\n",
      "Epoch 102/1000\n",
      "0s - loss: 47.8744 - val_loss: 39.8680\n",
      "Epoch 103/1000\n",
      "0s - loss: 49.8449 - val_loss: 44.4815\n",
      "Epoch 104/1000\n",
      "0s - loss: 49.8875 - val_loss: 37.4492\n",
      "Epoch 105/1000\n",
      "0s - loss: 46.8679 - val_loss: 36.8851\n",
      "Epoch 106/1000\n",
      "0s - loss: 45.3582 - val_loss: 36.5148\n",
      "Epoch 107/1000\n",
      "0s - loss: 45.8753 - val_loss: 40.1150\n",
      "Epoch 108/1000\n",
      "0s - loss: 46.5516 - val_loss: 36.0211\n",
      "Epoch 109/1000\n",
      "0s - loss: 44.5022 - val_loss: 40.0291\n",
      "Epoch 110/1000\n",
      "0s - loss: 45.7317 - val_loss: 50.3404\n",
      "Epoch 111/1000\n",
      "0s - loss: 47.8779 - val_loss: 36.2398\n",
      "Epoch 112/1000\n",
      "0s - loss: 43.8113 - val_loss: 37.5584\n",
      "Epoch 113/1000\n",
      "0s - loss: 44.8715 - val_loss: 38.9203\n",
      "Epoch 114/1000\n",
      "0s - loss: 44.2013 - val_loss: 34.5311\n",
      "Epoch 115/1000\n",
      "0s - loss: 43.6475 - val_loss: 34.6059\n",
      "Epoch 116/1000\n",
      "0s - loss: 44.5418 - val_loss: 34.5002\n",
      "Epoch 117/1000\n",
      "0s - loss: 41.7839 - val_loss: 36.8173\n",
      "Epoch 118/1000\n",
      "0s - loss: 43.4076 - val_loss: 33.6336\n",
      "Epoch 119/1000\n",
      "0s - loss: 46.1111 - val_loss: 35.9827\n",
      "Epoch 120/1000\n",
      "0s - loss: 43.0669 - val_loss: 33.8848\n",
      "Epoch 121/1000\n",
      "0s - loss: 41.3438 - val_loss: 32.7153\n",
      "Epoch 122/1000\n",
      "0s - loss: 40.9635 - val_loss: 33.5432\n",
      "Epoch 123/1000\n",
      "0s - loss: 43.0216 - val_loss: 41.6702\n",
      "Epoch 124/1000\n",
      "0s - loss: 45.0702 - val_loss: 39.3504\n",
      "Epoch 125/1000\n",
      "0s - loss: 43.5412 - val_loss: 32.4579\n",
      "Epoch 126/1000\n",
      "0s - loss: 44.3445 - val_loss: 31.9858\n",
      "Epoch 127/1000\n",
      "0s - loss: 42.6770 - val_loss: 40.8222\n",
      "Epoch 128/1000\n",
      "0s - loss: 40.7050 - val_loss: 36.4089\n",
      "Epoch 129/1000\n",
      "0s - loss: 39.6816 - val_loss: 34.4896\n",
      "Epoch 130/1000\n",
      "0s - loss: 38.3193 - val_loss: 33.2408\n",
      "Epoch 131/1000\n",
      "0s - loss: 39.0816 - val_loss: 30.0985\n",
      "Epoch 132/1000\n",
      "0s - loss: 38.4805 - val_loss: 29.9797\n",
      "Epoch 133/1000\n",
      "0s - loss: 36.9768 - val_loss: 32.9796\n",
      "Epoch 134/1000\n",
      "0s - loss: 36.6028 - val_loss: 31.0508\n",
      "Epoch 135/1000\n",
      "0s - loss: 36.7699 - val_loss: 29.2439\n",
      "Epoch 136/1000\n",
      "0s - loss: 36.2542 - val_loss: 29.0350\n",
      "Epoch 137/1000\n",
      "0s - loss: 36.3022 - val_loss: 29.1621\n",
      "Epoch 138/1000\n",
      "0s - loss: 36.5391 - val_loss: 30.2183\n",
      "Epoch 139/1000\n",
      "0s - loss: 36.4805 - val_loss: 28.4777\n",
      "Epoch 140/1000\n",
      "0s - loss: 35.5016 - val_loss: 28.9688\n",
      "Epoch 141/1000\n",
      "0s - loss: 34.8908 - val_loss: 29.8176\n",
      "Epoch 142/1000\n",
      "0s - loss: 37.0372 - val_loss: 28.3971\n",
      "Epoch 143/1000\n",
      "0s - loss: 36.4497 - val_loss: 31.7878\n",
      "Epoch 144/1000\n",
      "0s - loss: 35.6088 - val_loss: 27.4384\n",
      "Epoch 145/1000\n",
      "0s - loss: 33.2913 - val_loss: 26.7338\n",
      "Epoch 146/1000\n",
      "0s - loss: 34.1102 - val_loss: 28.6263\n",
      "Epoch 147/1000\n",
      "0s - loss: 33.3728 - val_loss: 27.7509\n",
      "Epoch 148/1000\n",
      "0s - loss: 34.0237 - val_loss: 31.1909\n",
      "Epoch 149/1000\n",
      "0s - loss: 33.5749 - val_loss: 38.0398\n",
      "Epoch 150/1000\n",
      "0s - loss: 34.7763 - val_loss: 25.5191\n",
      "Epoch 151/1000\n",
      "0s - loss: 32.5651 - val_loss: 25.7595\n",
      "Epoch 152/1000\n",
      "0s - loss: 31.9215 - val_loss: 25.4489\n",
      "Epoch 153/1000\n",
      "0s - loss: 31.3945 - val_loss: 25.2695\n",
      "Epoch 154/1000\n",
      "0s - loss: 33.3240 - val_loss: 24.8308\n",
      "Epoch 155/1000\n",
      "0s - loss: 35.3298 - val_loss: 33.8903\n",
      "Epoch 156/1000\n",
      "0s - loss: 33.2278 - val_loss: 24.0286\n",
      "Epoch 157/1000\n",
      "0s - loss: 31.4190 - val_loss: 24.7858\n",
      "Epoch 158/1000\n",
      "0s - loss: 31.2651 - val_loss: 23.5672\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 29.2232 - val_loss: 23.2536\n",
      "Epoch 160/1000\n",
      "0s - loss: 30.6664 - val_loss: 23.1426\n",
      "Epoch 161/1000\n",
      "0s - loss: 30.5753 - val_loss: 22.8813\n",
      "Epoch 162/1000\n",
      "0s - loss: 30.0652 - val_loss: 24.1833\n",
      "Epoch 163/1000\n",
      "0s - loss: 29.8365 - val_loss: 25.3662\n",
      "Epoch 164/1000\n",
      "0s - loss: 27.7280 - val_loss: 26.7799\n",
      "Epoch 165/1000\n",
      "0s - loss: 27.7709 - val_loss: 21.8562\n",
      "Epoch 166/1000\n",
      "0s - loss: 28.4948 - val_loss: 22.4689\n",
      "Epoch 167/1000\n",
      "0s - loss: 27.1511 - val_loss: 21.4182\n",
      "Epoch 168/1000\n",
      "0s - loss: 26.8504 - val_loss: 21.4853\n",
      "Epoch 169/1000\n",
      "0s - loss: 27.6430 - val_loss: 24.8912\n",
      "Epoch 170/1000\n",
      "0s - loss: 28.8525 - val_loss: 20.7471\n",
      "Epoch 171/1000\n",
      "0s - loss: 26.3165 - val_loss: 21.5974\n",
      "Epoch 172/1000\n",
      "0s - loss: 26.1628 - val_loss: 24.8967\n",
      "Epoch 173/1000\n",
      "0s - loss: 26.7124 - val_loss: 20.0761\n",
      "Epoch 174/1000\n",
      "0s - loss: 25.3080 - val_loss: 21.6813\n",
      "Epoch 175/1000\n",
      "0s - loss: 25.5181 - val_loss: 22.9930\n",
      "Epoch 176/1000\n",
      "0s - loss: 26.3888 - val_loss: 19.8633\n",
      "Epoch 177/1000\n",
      "0s - loss: 24.9384 - val_loss: 19.6018\n",
      "Epoch 178/1000\n",
      "0s - loss: 24.7010 - val_loss: 21.1180\n",
      "Epoch 179/1000\n",
      "0s - loss: 24.5734 - val_loss: 19.4582\n",
      "Epoch 180/1000\n",
      "0s - loss: 25.8139 - val_loss: 20.6831\n",
      "Epoch 181/1000\n",
      "0s - loss: 25.3256 - val_loss: 24.3703\n",
      "Epoch 182/1000\n",
      "0s - loss: 26.8676 - val_loss: 18.2375\n",
      "Epoch 183/1000\n",
      "0s - loss: 23.6566 - val_loss: 21.5453\n",
      "Epoch 184/1000\n",
      "0s - loss: 24.7290 - val_loss: 18.3838\n",
      "Epoch 185/1000\n",
      "0s - loss: 22.9519 - val_loss: 18.2743\n",
      "Epoch 186/1000\n",
      "0s - loss: 23.3134 - val_loss: 21.5656\n",
      "Epoch 187/1000\n",
      "0s - loss: 22.3804 - val_loss: 18.0823\n",
      "Epoch 188/1000\n",
      "0s - loss: 23.5374 - val_loss: 19.0888\n",
      "Epoch 189/1000\n",
      "0s - loss: 24.0655 - val_loss: 19.3168\n",
      "Epoch 190/1000\n",
      "0s - loss: 24.5402 - val_loss: 21.8826\n",
      "Epoch 191/1000\n",
      "0s - loss: 24.5016 - val_loss: 17.2385\n",
      "Epoch 192/1000\n",
      "0s - loss: 21.4770 - val_loss: 16.4455\n",
      "Epoch 193/1000\n",
      "0s - loss: 20.8461 - val_loss: 17.5762\n",
      "Epoch 194/1000\n",
      "0s - loss: 21.3919 - val_loss: 26.2551\n",
      "Epoch 195/1000\n",
      "0s - loss: 24.4616 - val_loss: 16.1563\n",
      "Epoch 196/1000\n",
      "0s - loss: 20.5972 - val_loss: 19.1484\n",
      "Epoch 197/1000\n",
      "0s - loss: 21.8330 - val_loss: 16.6666\n",
      "Epoch 198/1000\n",
      "0s - loss: 20.0637 - val_loss: 15.8330\n",
      "Epoch 199/1000\n",
      "0s - loss: 19.7801 - val_loss: 15.1975\n",
      "Epoch 200/1000\n",
      "0s - loss: 19.5949 - val_loss: 14.9998\n",
      "Epoch 201/1000\n",
      "0s - loss: 19.0803 - val_loss: 15.6268\n",
      "Epoch 202/1000\n",
      "0s - loss: 19.8872 - val_loss: 15.0101\n",
      "Epoch 203/1000\n",
      "0s - loss: 20.6472 - val_loss: 16.4937\n",
      "Epoch 204/1000\n",
      "0s - loss: 21.1803 - val_loss: 15.0887\n",
      "Epoch 205/1000\n",
      "0s - loss: 19.1293 - val_loss: 16.1603\n",
      "Epoch 206/1000\n",
      "0s - loss: 19.3540 - val_loss: 14.5051\n",
      "Epoch 207/1000\n",
      "0s - loss: 19.0861 - val_loss: 14.0659\n",
      "Epoch 208/1000\n",
      "0s - loss: 20.0763 - val_loss: 17.2936\n",
      "Epoch 209/1000\n",
      "0s - loss: 19.3362 - val_loss: 16.1434\n",
      "Epoch 210/1000\n",
      "0s - loss: 18.9124 - val_loss: 13.5325\n",
      "Epoch 211/1000\n",
      "0s - loss: 17.4835 - val_loss: 13.9402\n",
      "Epoch 212/1000\n",
      "0s - loss: 18.7600 - val_loss: 13.3332\n",
      "Epoch 213/1000\n",
      "0s - loss: 17.0568 - val_loss: 13.4893\n",
      "Epoch 214/1000\n",
      "0s - loss: 17.1531 - val_loss: 13.4813\n",
      "Epoch 215/1000\n",
      "0s - loss: 16.7537 - val_loss: 13.6394\n",
      "Epoch 216/1000\n",
      "0s - loss: 17.5496 - val_loss: 13.4253\n",
      "Epoch 217/1000\n",
      "0s - loss: 16.8527 - val_loss: 12.6675\n",
      "Epoch 218/1000\n",
      "0s - loss: 17.2600 - val_loss: 15.5984\n",
      "Epoch 219/1000\n",
      "0s - loss: 17.1246 - val_loss: 12.3903\n",
      "Epoch 220/1000\n",
      "0s - loss: 16.0569 - val_loss: 12.2683\n",
      "Epoch 221/1000\n",
      "0s - loss: 16.7061 - val_loss: 12.7226\n",
      "Epoch 222/1000\n",
      "0s - loss: 16.1695 - val_loss: 12.1637\n",
      "Epoch 223/1000\n",
      "0s - loss: 16.3988 - val_loss: 14.0050\n",
      "Epoch 224/1000\n",
      "0s - loss: 16.0559 - val_loss: 11.9800\n",
      "Epoch 225/1000\n",
      "0s - loss: 16.1956 - val_loss: 13.7799\n",
      "Epoch 226/1000\n",
      "0s - loss: 16.1313 - val_loss: 11.8908\n",
      "Epoch 227/1000\n",
      "0s - loss: 16.5879 - val_loss: 13.3912\n",
      "Epoch 228/1000\n",
      "0s - loss: 15.7246 - val_loss: 11.4885\n",
      "Epoch 229/1000\n",
      "0s - loss: 14.9209 - val_loss: 11.4689\n",
      "Epoch 230/1000\n",
      "0s - loss: 15.0700 - val_loss: 12.1379\n",
      "Epoch 231/1000\n",
      "0s - loss: 14.4831 - val_loss: 14.7760\n",
      "Epoch 232/1000\n",
      "0s - loss: 16.0745 - val_loss: 14.6355\n",
      "Epoch 233/1000\n",
      "0s - loss: 16.0523 - val_loss: 11.0717\n",
      "Epoch 234/1000\n",
      "0s - loss: 15.4527 - val_loss: 11.1680\n",
      "Epoch 235/1000\n",
      "0s - loss: 17.2822 - val_loss: 11.8712\n",
      "Epoch 236/1000\n",
      "0s - loss: 15.4888 - val_loss: 11.0159\n",
      "Epoch 237/1000\n",
      "0s - loss: 15.2521 - val_loss: 12.0803\n",
      "Epoch 238/1000\n",
      "0s - loss: 14.4841 - val_loss: 11.0963\n",
      "Epoch 239/1000\n",
      "0s - loss: 14.3920 - val_loss: 11.2980\n",
      "Epoch 240/1000\n",
      "0s - loss: 14.6541 - val_loss: 10.8019\n",
      "Epoch 241/1000\n",
      "0s - loss: 13.7596 - val_loss: 10.5111\n",
      "Epoch 242/1000\n",
      "0s - loss: 14.5537 - val_loss: 13.2587\n",
      "Epoch 243/1000\n",
      "0s - loss: 15.8465 - val_loss: 13.3238\n",
      "Epoch 244/1000\n",
      "0s - loss: 15.7230 - val_loss: 10.3419\n",
      "Epoch 245/1000\n",
      "0s - loss: 14.2203 - val_loss: 20.4007\n",
      "Epoch 246/1000\n",
      "0s - loss: 16.7251 - val_loss: 10.2206\n",
      "Epoch 247/1000\n",
      "0s - loss: 15.3724 - val_loss: 10.8474\n",
      "Epoch 248/1000\n",
      "0s - loss: 16.9658 - val_loss: 16.3308\n",
      "Epoch 249/1000\n",
      "0s - loss: 15.4515 - val_loss: 11.8733\n",
      "Epoch 250/1000\n",
      "0s - loss: 13.7308 - val_loss: 12.3843\n",
      "Epoch 251/1000\n",
      "0s - loss: 15.6753 - val_loss: 10.4069\n",
      "Epoch 252/1000\n",
      "0s - loss: 15.1786 - val_loss: 14.2970\n",
      "Epoch 00251: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16962c0f198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "cars = df['name']\n",
    "df.drop('name',1,inplace=True)\n",
    "missing_median(df, 'horsepower')\n",
    "x,y = to_xy(df,\"mpg\")\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(10,input_dim=x.shape[1],activation='relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score MSE 14.297036170959473\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "\n",
    "score=metrics.mean_squared_error(pred,y_test)\n",
    "print('Final Score MSE {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score is 3.781142234802246\n"
     ]
    }
   ],
   "source": [
    "score=np.sqrt(score)\n",
    "print('RMSE score is {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #{} 1\n",
      "Epoch 00255: early stopping\n",
      "Fold score (RMSE) is 8.586132049560547\n",
      "Fold #{} 2\n",
      "Epoch 00565: early stopping\n",
      "Fold score (RMSE) is 4.011175632476807\n",
      "Fold #{} 3\n",
      "Epoch 00448: early stopping\n",
      "Fold score (RMSE) is 4.94875955581665\n",
      "Fold #{} 4\n",
      "Epoch 00031: early stopping\n",
      "Fold score (RMSE) is 15.436417579650879\n",
      "Fold #{} 5\n",
      "Epoch 00406: early stopping\n",
      "Fold score (RMSE) is 3.913360357284546\n",
      "Final out-of-sample score (RMSE): 8.562261581420898\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "path ='./data/'\n",
    "\n",
    "filename_read=os.path.join(path,'auto-mpg.csv')\n",
    "filename_write=os.path.join(path,'mod4-2_test.csv')\n",
    "df=pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "#Shuffle\n",
    "np.random.seed(42)\n",
    "df=df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#Preprocess\n",
    "cars=df['name']\n",
    "df.drop('name',1,inplace=True)\n",
    "missing_median(df,'horsepower')\n",
    "\n",
    "#2D matrix\n",
    "x,y=to_xy(df,'mpg')\n",
    "\n",
    "#Cross_Validate\n",
    "kf=KFold(5)\n",
    "\n",
    "oos_y=[]\n",
    "oos_pred=[]\n",
    "fold=0\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print('Fold #{}',format(fold))\n",
    "    \n",
    "    x_train=x[train]\n",
    "    y_train=y[train]\n",
    "    x_test=x[test]\n",
    "    y_test=y[test]\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1],activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor=EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5,verbose=1,mode='auto')\n",
    "    model.fit(x_train,y_train, validation_data=(x_test,y_test), callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    \n",
    "    pred=model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)\n",
    "    \n",
    "    #Measure this fold's RMSE\n",
    "    score=np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print('Fold score (RMSE) is {}'.format(score))\n",
    "\n",
    "#Build the oos prediction list and calculate the error\n",
    "oos_y=np.concatenate(oos_y)\n",
    "oos_pred=np.concatenate(oos_pred)\n",
    "score=np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(\"Final out-of-sample score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "#Cross_validation prediction\n",
    "oos_y=pd.DataFrame(oos_y)\n",
    "oos_pred=pd.DataFrame(oos_pred)\n",
    "oosDF=pd.concat([df,oos_y,oos_pred],axis=1)\n",
    "oosDF.to_csv(filename_write, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>19.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>21.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>31.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>39.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>19.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>33.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>28.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>40.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>21.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>37.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    33.000000\n",
       "1    28.000000\n",
       "2    19.000000\n",
       "3    13.000000\n",
       "4    14.000000\n",
       "5    27.000000\n",
       "6    24.000000\n",
       "7    13.000000\n",
       "8    17.000000\n",
       "9    21.000000\n",
       "10   15.000000\n",
       "11   38.000000\n",
       "12   26.000000\n",
       "13   15.000000\n",
       "14   25.000000\n",
       "15   12.000000\n",
       "16   31.000000\n",
       "17   17.000000\n",
       "18   16.000000\n",
       "19   31.000000\n",
       "20   22.000000\n",
       "21   22.000000\n",
       "22   22.000000\n",
       "23   33.500000\n",
       "24   18.000000\n",
       "25   44.000000\n",
       "26   26.000000\n",
       "27   24.500000\n",
       "28   18.100000\n",
       "29   12.000000\n",
       "..         ...\n",
       "368  39.000000\n",
       "369  26.000000\n",
       "370  19.200001\n",
       "371  24.000000\n",
       "372  28.000000\n",
       "373  17.000000\n",
       "374  21.600000\n",
       "375  22.000000\n",
       "376  31.900000\n",
       "377  39.099998\n",
       "378  19.400000\n",
       "379  33.500000\n",
       "380  24.000000\n",
       "381  26.000000\n",
       "382  31.000000\n",
       "383  28.100000\n",
       "384  18.000000\n",
       "385  27.000000\n",
       "386  13.000000\n",
       "387  40.900002\n",
       "388  13.000000\n",
       "389  15.000000\n",
       "390  31.000000\n",
       "391  25.000000\n",
       "392  16.000000\n",
       "393  19.000000\n",
       "394  12.000000\n",
       "395  21.100000\n",
       "396  37.700001\n",
       "397  26.000000\n",
       "\n",
       "[398 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1795</td>\n",
       "      <td>17.4</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>21.792652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>30.394543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2634</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.022930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3940</td>\n",
       "      <td>13.2</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.737759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4237</td>\n",
       "      <td>14.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.459072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.5</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>19.457409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2865</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>29.817959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4735</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.726604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4060</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>32.792171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>2875</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.673367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-4.618886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>15.0</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>22.472698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>20.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>21.625561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3892</td>\n",
       "      <td>12.5</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.850582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2542</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.236645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4955</td>\n",
       "      <td>11.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>20.373333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2575</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.687954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3140</td>\n",
       "      <td>13.6</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.426830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4220</td>\n",
       "      <td>11.1</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.653713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>17.6</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>22.828411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2511</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>27.499752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.108257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2835</td>\n",
       "      <td>14.7</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>12.965221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2075</td>\n",
       "      <td>15.9</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>20.354336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.679104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>29.778210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>22.131435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24.5</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2740</td>\n",
       "      <td>16.0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>26.369656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3410</td>\n",
       "      <td>15.1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>19.310894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>4906</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>20.498486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>39.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1875</td>\n",
       "      <td>16.4</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>31.643906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2265</td>\n",
       "      <td>18.2</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.851582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>3535</td>\n",
       "      <td>19.2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>22.524069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2430</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.508301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>16.5</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>27.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3907</td>\n",
       "      <td>21.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.236925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>21.6</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2795</td>\n",
       "      <td>15.7</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>26.356876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3233</td>\n",
       "      <td>15.4</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.134233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1925</td>\n",
       "      <td>14.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>30.635166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>39.1</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1755</td>\n",
       "      <td>16.9</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>33.126404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>19.4</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3210</td>\n",
       "      <td>17.2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>23.455105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>33.5</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2556</td>\n",
       "      <td>13.2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>26.357635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2489</td>\n",
       "      <td>15.0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>26.447285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2451</td>\n",
       "      <td>16.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.811178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.819614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>28.1</td>\n",
       "      <td>4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3230</td>\n",
       "      <td>20.4</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>27.309795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2945</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.770149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2735</td>\n",
       "      <td>18.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.963066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3988</td>\n",
       "      <td>13.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.335494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>40.9</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>1835</td>\n",
       "      <td>17.3</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>40.900002</td>\n",
       "      <td>29.842117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3870</td>\n",
       "      <td>15.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.491524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3399</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.398045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.964525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2672</td>\n",
       "      <td>17.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.259069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4190</td>\n",
       "      <td>13.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.454441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2330</td>\n",
       "      <td>13.5</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>26.511971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4499</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.982289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>21.1</td>\n",
       "      <td>4</td>\n",
       "      <td>134.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2515</td>\n",
       "      <td>14.8</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>27.853374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>37.7</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2050</td>\n",
       "      <td>17.3</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>37.700001</td>\n",
       "      <td>32.491150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.501753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0    33.0          4          91.0        53.0    1795          17.4    76   \n",
       "1    28.0          4         120.0        79.0    2625          18.6    82   \n",
       "2    19.0          6         232.0       100.0    2634          13.0    71   \n",
       "3    13.0          8         318.0       150.0    3940          13.2    76   \n",
       "4    14.0          8         318.0       150.0    4237          14.5    73   \n",
       "5    27.0          4          97.0        88.0    2100          16.5    72   \n",
       "6    24.0          4         140.0        92.0    2865          16.4    82   \n",
       "7    13.0          8         440.0       215.0    4735          11.0    73   \n",
       "8    17.0          8         260.0       110.0    4060          19.0    77   \n",
       "9    21.0          6         200.0        93.5    2875          17.0    74   \n",
       "10   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "11   38.0          4          91.0        67.0    1965          15.0    82   \n",
       "12   26.0          4          91.0        70.0    1955          20.5    71   \n",
       "13   15.0          8         304.0       150.0    3892          12.5    72   \n",
       "14   25.0          4         140.0        75.0    2542          17.0    74   \n",
       "15   12.0          8         383.0       180.0    4955          11.5    71   \n",
       "16   31.0          4         112.0        85.0    2575          16.2    82   \n",
       "17   17.0          6         163.0       125.0    3140          13.6    78   \n",
       "18   16.0          8         400.0       180.0    4220          11.1    77   \n",
       "19   31.0          4          91.0        68.0    1970          17.6    82   \n",
       "20   22.0          4         121.0        76.0    2511          18.0    72   \n",
       "21   22.0          6         198.0        95.0    2833          15.5    70   \n",
       "22   22.0          6         232.0       112.0    2835          14.7    82   \n",
       "23   33.5          4          98.0        83.0    2075          15.9    77   \n",
       "24   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "25   44.0          4          97.0        52.0    2130          24.6    82   \n",
       "26   26.0          4          98.0        90.0    2265          15.5    73   \n",
       "27   24.5          4         151.0        88.0    2740          16.0    77   \n",
       "28   18.1          6         258.0       120.0    3410          15.1    78   \n",
       "29   12.0          8         400.0       167.0    4906          12.5    73   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "368  39.0          4          86.0        64.0    1875          16.4    81   \n",
       "369  26.0          4          97.0        75.0    2265          18.2    77   \n",
       "370  19.2          6         231.0       105.0    3535          19.2    78   \n",
       "371  24.0          4         107.0        90.0    2430          14.5    70   \n",
       "372  28.0          4         151.0        90.0    2678          16.5    80   \n",
       "373  17.0          6         231.0       110.0    3907          21.0    75   \n",
       "374  21.6          4         121.0       115.0    2795          15.7    78   \n",
       "375  22.0          6         225.0       100.0    3233          15.4    76   \n",
       "376  31.9          4          89.0        71.0    1925          14.0    79   \n",
       "377  39.1          4          79.0        58.0    1755          16.9    81   \n",
       "378  19.4          6         232.0        90.0    3210          17.2    78   \n",
       "379  33.5          4         151.0        90.0    2556          13.2    79   \n",
       "380  24.0          4         120.0        97.0    2489          15.0    74   \n",
       "381  26.0          4         122.0        80.0    2451          16.5    74   \n",
       "382  31.0          4          79.0        67.0    2000          16.0    74   \n",
       "383  28.1          4         141.0        80.0    3230          20.4    81   \n",
       "384  18.0          6         232.0       100.0    2945          16.0    73   \n",
       "385  27.0          4         151.0        90.0    2735          18.0    82   \n",
       "386  13.0          8         350.0       145.0    3988          13.0    73   \n",
       "387  40.9          4          85.0        93.5    1835          17.3    80   \n",
       "388  13.0          8         302.0       130.0    3870          15.0    76   \n",
       "389  15.0          8         318.0       150.0    3399          11.0    73   \n",
       "390  31.0          4         119.0        82.0    2720          19.4    82   \n",
       "391  25.0          4         110.0        87.0    2672          17.5    70   \n",
       "392  16.0          8         318.0       150.0    4190          13.0    76   \n",
       "393  19.0          3          70.0        97.0    2330          13.5    72   \n",
       "394  12.0          8         350.0       180.0    4499          12.5    73   \n",
       "395  21.1          4         134.0        95.0    2515          14.8    78   \n",
       "396  37.7          4          89.0        62.0    2050          17.3    81   \n",
       "397  26.0          4          97.0        46.0    1950          21.0    73   \n",
       "\n",
       "     origin          0          0  \n",
       "0         3  33.000000  21.792652  \n",
       "1         1  28.000000  30.394543  \n",
       "2         1  19.000000  11.022930  \n",
       "3         1  13.000000  14.737759  \n",
       "4         1  14.000000  20.459072  \n",
       "5         3  27.000000  19.457409  \n",
       "6         1  24.000000  29.817959  \n",
       "7         1  13.000000   2.726604  \n",
       "8         1  17.000000  32.792171  \n",
       "9         1  21.000000  20.673367  \n",
       "10        1  15.000000  -4.618886  \n",
       "11        3  38.000000  22.472698  \n",
       "12        1  26.000000  21.625561  \n",
       "13        1  15.000000  14.850582  \n",
       "14        1  25.000000  26.236645  \n",
       "15        1  12.000000  20.373333  \n",
       "16        1  31.000000  28.687954  \n",
       "17        2  17.000000  23.426830  \n",
       "18        1  16.000000   4.653713  \n",
       "19        3  31.000000  22.828411  \n",
       "20        2  22.000000  27.499752  \n",
       "21        1  22.000000  19.108257  \n",
       "22        1  22.000000  12.965221  \n",
       "23        1  33.500000  20.354336  \n",
       "24        1  18.000000  10.679104  \n",
       "25        2  44.000000  29.778210  \n",
       "26        2  26.000000  22.131435  \n",
       "27        1  24.500000  26.369656  \n",
       "28        1  18.100000  19.310894  \n",
       "29        1  12.000000  20.498486  \n",
       "..      ...        ...        ...  \n",
       "368       1  39.000000  31.643906  \n",
       "369       3  26.000000  29.851582  \n",
       "370       1  19.200001  22.524069  \n",
       "371       2  24.000000  24.508301  \n",
       "372       1  28.000000  27.001900  \n",
       "373       1  17.000000  20.236925  \n",
       "374       2  21.600000  26.356876  \n",
       "375       1  22.000000  22.134233  \n",
       "376       2  31.900000  30.635166  \n",
       "377       3  39.099998  33.126404  \n",
       "378       1  19.400000  23.455105  \n",
       "379       1  33.500000  26.357635  \n",
       "380       3  24.000000  26.447285  \n",
       "381       1  26.000000  25.811178  \n",
       "382       2  31.000000  28.819614  \n",
       "383       2  28.100000  27.309795  \n",
       "384       1  18.000000  21.770149  \n",
       "385       1  27.000000  27.963066  \n",
       "386       1  13.000000  15.335494  \n",
       "387       2  40.900002  29.842117  \n",
       "388       1  13.000000  18.491524  \n",
       "389       1  15.000000  17.398045  \n",
       "390       1  31.000000  28.964525  \n",
       "391       2  25.000000  24.259069  \n",
       "392       1  16.000000  16.454441  \n",
       "393       3  19.000000  26.511971  \n",
       "394       1  12.000000  12.982289  \n",
       "395       3  21.100000  27.853374  \n",
       "396       3  37.700001  32.491150  \n",
       "397       2  26.000000  29.501753  \n",
       "\n",
       "[398 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oosDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1795</td>\n",
       "      <td>17.4</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2634</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3940</td>\n",
       "      <td>13.2</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4237</td>\n",
       "      <td>14.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>16.5</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2865</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4735</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4060</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>2875</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>15.0</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>20.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3892</td>\n",
       "      <td>12.5</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2542</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4955</td>\n",
       "      <td>11.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2575</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3140</td>\n",
       "      <td>13.6</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4220</td>\n",
       "      <td>11.1</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>17.6</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2511</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2835</td>\n",
       "      <td>14.7</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2075</td>\n",
       "      <td>15.9</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24.5</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2740</td>\n",
       "      <td>16.0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3410</td>\n",
       "      <td>15.1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>4906</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>39.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1875</td>\n",
       "      <td>16.4</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2265</td>\n",
       "      <td>18.2</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>3535</td>\n",
       "      <td>19.2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2430</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>16.5</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3907</td>\n",
       "      <td>21.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>21.6</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2795</td>\n",
       "      <td>15.7</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3233</td>\n",
       "      <td>15.4</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1925</td>\n",
       "      <td>14.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>39.1</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1755</td>\n",
       "      <td>16.9</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>19.4</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3210</td>\n",
       "      <td>17.2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>33.5</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2556</td>\n",
       "      <td>13.2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2489</td>\n",
       "      <td>15.0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2451</td>\n",
       "      <td>16.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>28.1</td>\n",
       "      <td>4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3230</td>\n",
       "      <td>20.4</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2945</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2735</td>\n",
       "      <td>18.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3988</td>\n",
       "      <td>13.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>40.9</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>1835</td>\n",
       "      <td>17.3</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3870</td>\n",
       "      <td>15.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3399</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2672</td>\n",
       "      <td>17.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4190</td>\n",
       "      <td>13.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2330</td>\n",
       "      <td>13.5</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4499</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>21.1</td>\n",
       "      <td>4</td>\n",
       "      <td>134.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2515</td>\n",
       "      <td>14.8</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>37.7</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2050</td>\n",
       "      <td>17.3</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0    33.0          4          91.0        53.0    1795          17.4    76   \n",
       "1    28.0          4         120.0        79.0    2625          18.6    82   \n",
       "2    19.0          6         232.0       100.0    2634          13.0    71   \n",
       "3    13.0          8         318.0       150.0    3940          13.2    76   \n",
       "4    14.0          8         318.0       150.0    4237          14.5    73   \n",
       "5    27.0          4          97.0        88.0    2100          16.5    72   \n",
       "6    24.0          4         140.0        92.0    2865          16.4    82   \n",
       "7    13.0          8         440.0       215.0    4735          11.0    73   \n",
       "8    17.0          8         260.0       110.0    4060          19.0    77   \n",
       "9    21.0          6         200.0        93.5    2875          17.0    74   \n",
       "10   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "11   38.0          4          91.0        67.0    1965          15.0    82   \n",
       "12   26.0          4          91.0        70.0    1955          20.5    71   \n",
       "13   15.0          8         304.0       150.0    3892          12.5    72   \n",
       "14   25.0          4         140.0        75.0    2542          17.0    74   \n",
       "15   12.0          8         383.0       180.0    4955          11.5    71   \n",
       "16   31.0          4         112.0        85.0    2575          16.2    82   \n",
       "17   17.0          6         163.0       125.0    3140          13.6    78   \n",
       "18   16.0          8         400.0       180.0    4220          11.1    77   \n",
       "19   31.0          4          91.0        68.0    1970          17.6    82   \n",
       "20   22.0          4         121.0        76.0    2511          18.0    72   \n",
       "21   22.0          6         198.0        95.0    2833          15.5    70   \n",
       "22   22.0          6         232.0       112.0    2835          14.7    82   \n",
       "23   33.5          4          98.0        83.0    2075          15.9    77   \n",
       "24   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "25   44.0          4          97.0        52.0    2130          24.6    82   \n",
       "26   26.0          4          98.0        90.0    2265          15.5    73   \n",
       "27   24.5          4         151.0        88.0    2740          16.0    77   \n",
       "28   18.1          6         258.0       120.0    3410          15.1    78   \n",
       "29   12.0          8         400.0       167.0    4906          12.5    73   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "368  39.0          4          86.0        64.0    1875          16.4    81   \n",
       "369  26.0          4          97.0        75.0    2265          18.2    77   \n",
       "370  19.2          6         231.0       105.0    3535          19.2    78   \n",
       "371  24.0          4         107.0        90.0    2430          14.5    70   \n",
       "372  28.0          4         151.0        90.0    2678          16.5    80   \n",
       "373  17.0          6         231.0       110.0    3907          21.0    75   \n",
       "374  21.6          4         121.0       115.0    2795          15.7    78   \n",
       "375  22.0          6         225.0       100.0    3233          15.4    76   \n",
       "376  31.9          4          89.0        71.0    1925          14.0    79   \n",
       "377  39.1          4          79.0        58.0    1755          16.9    81   \n",
       "378  19.4          6         232.0        90.0    3210          17.2    78   \n",
       "379  33.5          4         151.0        90.0    2556          13.2    79   \n",
       "380  24.0          4         120.0        97.0    2489          15.0    74   \n",
       "381  26.0          4         122.0        80.0    2451          16.5    74   \n",
       "382  31.0          4          79.0        67.0    2000          16.0    74   \n",
       "383  28.1          4         141.0        80.0    3230          20.4    81   \n",
       "384  18.0          6         232.0       100.0    2945          16.0    73   \n",
       "385  27.0          4         151.0        90.0    2735          18.0    82   \n",
       "386  13.0          8         350.0       145.0    3988          13.0    73   \n",
       "387  40.9          4          85.0        93.5    1835          17.3    80   \n",
       "388  13.0          8         302.0       130.0    3870          15.0    76   \n",
       "389  15.0          8         318.0       150.0    3399          11.0    73   \n",
       "390  31.0          4         119.0        82.0    2720          19.4    82   \n",
       "391  25.0          4         110.0        87.0    2672          17.5    70   \n",
       "392  16.0          8         318.0       150.0    4190          13.0    76   \n",
       "393  19.0          3          70.0        97.0    2330          13.5    72   \n",
       "394  12.0          8         350.0       180.0    4499          12.5    73   \n",
       "395  21.1          4         134.0        95.0    2515          14.8    78   \n",
       "396  37.7          4          89.0        62.0    2050          17.3    81   \n",
       "397  26.0          4          97.0        46.0    1950          21.0    73   \n",
       "\n",
       "     origin  \n",
       "0         3  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "5         3  \n",
       "6         1  \n",
       "7         1  \n",
       "8         1  \n",
       "9         1  \n",
       "10        1  \n",
       "11        3  \n",
       "12        1  \n",
       "13        1  \n",
       "14        1  \n",
       "15        1  \n",
       "16        1  \n",
       "17        2  \n",
       "18        1  \n",
       "19        3  \n",
       "20        2  \n",
       "21        1  \n",
       "22        1  \n",
       "23        1  \n",
       "24        1  \n",
       "25        2  \n",
       "26        2  \n",
       "27        1  \n",
       "28        1  \n",
       "29        1  \n",
       "..      ...  \n",
       "368       1  \n",
       "369       3  \n",
       "370       1  \n",
       "371       2  \n",
       "372       1  \n",
       "373       1  \n",
       "374       2  \n",
       "375       1  \n",
       "376       2  \n",
       "377       3  \n",
       "378       1  \n",
       "379       1  \n",
       "380       3  \n",
       "381       1  \n",
       "382       2  \n",
       "383       2  \n",
       "384       1  \n",
       "385       1  \n",
       "386       1  \n",
       "387       2  \n",
       "388       1  \n",
       "389       1  \n",
       "390       1  \n",
       "391       2  \n",
       "392       1  \n",
       "393       3  \n",
       "394       1  \n",
       "395       3  \n",
       "396       3  \n",
       "397       2  \n",
       "\n",
       "[398 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
